<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>进阶教程：给AI装上&quot;逻辑大脑&quot;，打造金融级稳定的多轮对话Agent（Dify实战） | 吏部侍郎</title><meta name="author" content="华子"><meta name="copyright" content="华子"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="之前，我们讨论过一次怎么样使用dify来构建多轮对话。保姆级教程：手把手教你用Dify实现完美多轮对话（附Chatflow和提示词）这个名字取得还可以，哈哈。但是实际生产使用会存在一些问题，评论区也有说到。  问题一：多轮对话时, 有些代词在回答的答案中, 只将的用户的问题当作上下文, 有时拼写不出完整的问题.   问题二：query改写节点不能开记忆，把之前对话合并成文本放进user promp">
<meta property="og:type" content="article">
<meta property="og:title" content="进阶教程：给AI装上&quot;逻辑大脑&quot;，打造金融级稳定的多轮对话Agent（Dify实战）">
<meta property="og:url" content="https://www.wenhuateng.top/posts/6066dc27/index.html">
<meta property="og:site_name" content="吏部侍郎">
<meta property="og:description" content="之前，我们讨论过一次怎么样使用dify来构建多轮对话。保姆级教程：手把手教你用Dify实现完美多轮对话（附Chatflow和提示词）这个名字取得还可以，哈哈。但是实际生产使用会存在一些问题，评论区也有说到。  问题一：多轮对话时, 有些代词在回答的答案中, 只将的用户的问题当作上下文, 有时拼写不出完整的问题.   问题二：query改写节点不能开记忆，把之前对话合并成文本放进user promp">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://wenhua-image.oss-cn-beijing.aliyuncs.com/%E5%BE%AE%E4%BF%A1%E5%85%AC%E4%BC%97%E5%8F%B7/%E5%B0%81%E9%9D%A2%E5%9B%BE.png">
<meta property="article:published_time" content="2026-01-21T14:21:51.000Z">
<meta property="article:modified_time" content="2026-01-21T15:24:42.352Z">
<meta property="article:author" content="华子">
<meta property="article:tag" content="Dify">
<meta property="article:tag" content="Agent">
<meta property="article:tag" content="LLM">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="https://wenhua-image.oss-cn-beijing.aliyuncs.com/%E5%BE%AE%E4%BF%A1%E5%85%AC%E4%BC%97%E5%8F%B7/%E5%B0%81%E9%9D%A2%E5%9B%BE.png"><script type="application/ld+json">{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "进阶教程：给AI装上\"逻辑大脑\"，打造金融级稳定的多轮对话Agent（Dify实战）",
  "url": "https://www.wenhuateng.top/posts/6066dc27/",
  "image": "https://wenhua-image.oss-cn-beijing.aliyuncs.com/%E5%BE%AE%E4%BF%A1%E5%85%AC%E4%BC%97%E5%8F%B7/%E5%B0%81%E9%9D%A2%E5%9B%BE.png",
  "datePublished": "2026-01-21T14:21:51.000Z",
  "dateModified": "2026-01-21T15:24:42.352Z",
  "author": [
    {
      "@type": "Person",
      "name": "华子",
      "url": "https://www.wenhuateng.top"
    }
  ]
}</script><link rel="shortcut icon" href="/img/favicon.svg"><link rel="canonical" href="https://www.wenhuateng.top/posts/6066dc27/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!false && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          theme === 'dark' ? activateDarkMode() : theme === 'light' ? activateLightMode() : null
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":false,"top_n_per_article":1,"unescape":false,"pagination":{"enable":false,"hitsPerPage":8},"languages":{"hits_empty":"未找到符合您查询的内容：${query}","hits_stats":"共找到 ${hits} 篇文章"}},
  translate: {"defaultEncoding":"繁","translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"簡"},
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false,"highlightFullpage":true,"highlightMacStyle":true},
  copy: {
    success: '复制成功',
    error: '复制失败',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyloadPlugin: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: true,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '进阶教程：给AI装上"逻辑大脑"，打造金融级稳定的多轮对话Agent（Dify实战）',
  isHighlightShrink: false,
  isToc: true,
  pageType: 'post'
}</script><meta name="generator" content="Hexo 7.3.0"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img text-center"><img src="/images/Happy.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data text-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">53</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">41</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">16</div></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="not-top-img fixed" id="page-header"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"><span class="site-name">吏部侍郎</span></a><a class="nav-page-title" href="/"><span class="site-name">进阶教程：给AI装上&quot;逻辑大脑&quot;，打造金融级稳定的多轮对话Agent（Dify实战）</span><span class="site-name"><i class="fa-solid fa-circle-arrow-left"></i><span>  返回首页</span></span></a></span><div id="menus"><div id="search-button"><span class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></span></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><div id="toggle-menu"><span class="site-page"><i class="fas fa-bars fa-fw"></i></span></div></div></nav></header><main class="layout" id="content-inner"><div id="post"><div id="post-info"><h1 class="post-title">进阶教程：给AI装上&quot;逻辑大脑&quot;，打造金融级稳定的多轮对话Agent（Dify实战）</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2026-01-21T14:21:51.000Z" title="发表于 2026-01-21 22:21:51">2026-01-21</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2026-01-21T15:24:42.352Z" title="更新于 2026-01-21 23:24:42">2026-01-21</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/AI%E7%BC%96%E7%A8%8B/">AI编程</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">总字数:</span><span class="word-count">4.2k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>13分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title=""><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">浏览量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div><article class="container post-content" id="article-container"><p>之前，我们讨论过一次怎么样使用dify来构建多轮对话。<br><a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/kl9W3ogVZfQ6eerFmvnZ-Q">保姆级教程：手把手教你用Dify实现完美多轮对话（附Chatflow和提示词）</a><br>这个名字取得还可以，哈哈。但是实际生产使用会存在一些问题，评论区也有说到。</p>
<blockquote>
<p>问题一：多轮对话时, 有些代词在回答的答案中, 只将的用户的问题当作上下文, 有时拼写不出完整的问题.</p>
</blockquote>
<blockquote>
<p>问题二：query改写节点不能开记忆，把之前对话合并成文本放进user prompt，再把温度降低，增加额外规则限制。会好一点。</p>
</blockquote>
<blockquote>
<p>问题三：用户输入和前文不相干，比如问完保险问其他话题（闲聊），这种情况如何分开做query改写防止污染？还想问下这样改写耗时会不会很久？小模型效果好吗？</p>
</blockquote>
<p>这些老师提到的问题其实都是同一个，如何确保问题改写节点，准确理解用户的问题，不要改写错误。此外还有：</p>
<blockquote>
<p>多轮对话时，如果A任务没有成，但是词槽或者说参数收集了一半，用户问多轮任务B，接这问C，这样大概率会造成信息丢失。</p>
</blockquote>
<blockquote>
<p>FAQ&#x2F;转人工等相关场景没有处理。</p>
</blockquote>
<blockquote>
<p>如何实现长期记忆。</p>
</blockquote>
<p><img src="https://wenhua-image.oss-cn-beijing.aliyuncs.com/%E5%BE%AE%E4%BF%A1%E5%85%AC%E4%BC%97%E5%8F%B7/%E5%A4%9A%E8%BD%AE%E5%AF%B9%E8%AF%9D%E7%9A%844%E5%A4%A7%E6%8C%91%E6%88%98.png" alt="多轮对话的4大挑战"><br>这些问题，我们依次来尝试解决一下，下面的整体思路，是结合了<code>bert</code>时代的状态机管理（或者说对话状态跟踪）和大模型的语义理解、分类、信息提取等相关能力。<br>为什么要用状态机呢？<br>我认为，对于私有化模型来说，一般都是开源的，不是最好的模型。二是，大模型是基于概率的，上下文、任务状态很容易丢失，一旦对话过程，即便是Gemini。另外一点就是，我在金融行业，金融行业对合规性更加重视，需要可靠可控的输出结果。<br><img src="https://wenhua-image.oss-cn-beijing.aliyuncs.com/%E5%BE%AE%E4%BF%A1%E5%85%AC%E4%BC%97%E5%8F%B7/%E7%8A%B6%E6%80%81%E6%9C%BA%E7%9A%84%E6%A0%B8%E5%BF%83%E4%BB%B7%E5%80%BC.png" alt="状态机的核心价值"><br>使用状态机，是为了显示的标识当前任务的状态。<br>我认为在提示词里面标识一下，肯定要比单纯使用LLM本身的记忆，能更好的提升任务完成率。<br>比如提示：#当前状态是查询天气信息收集中。</p>
<p>我们现在进入正题，一步步开始解决。当然，仍然是用dify演示，但是其他的工作流工具也是类似的。</p>
<h2 id="1-优化问题改写节点"><a href="#1-优化问题改写节点" class="headerlink" title="1. 优化问题改写节点"></a>1. 优化问题改写节点</h2><p><img src="https://wenhua-image.oss-cn-beijing.aliyuncs.com/%E5%BE%AE%E4%BF%A1%E5%85%AC%E4%BC%97%E5%8F%B7/%E5%AF%B9%E8%AF%9D%E5%8E%86%E5%8F%B2%E6%94%B6%E9%9B%86.png" alt="对话历史收集"><br>解决丢失系统回答，无法准确理解用户问题的情况。我的方法是，使用了代码节点，在所有的直接回复节点后面新增代码节点，然后赋值给会话变量。<br><img src="https://wenhua-image.oss-cn-beijing.aliyuncs.com/%E5%BE%AE%E4%BF%A1%E5%85%AC%E4%BC%97%E5%8F%B7/%E6%B1%87%E6%80%BB%E7%94%A8%E6%88%B7%E8%BE%93%E5%85%A5%E5%92%8CLLm%E5%9B%9E%E5%A4%8D.png"><br>最终的效果是这个样子的：</p>
<figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">user: 天气咋样啊</span><br><span class="line"><span class="section">assistant: 请问您想查询哪个城市的天气呢？</span></span><br><span class="line"><span class="section">---</span></span><br><span class="line">user: 北京</span><br><span class="line"><span class="section">assistant: 没问题，请问您想查询北京哪一天的天气呢？</span></span><br><span class="line"><span class="section">---</span></span><br><span class="line">user: 今天的</span><br><span class="line">assistant: 北京 · 2026-01-21  </span><br><span class="line">晴  </span><br><span class="line">-5℃ ~ 4℃  </span><br><span class="line">西北风3级 ｜ 湿度42%  </span><br><span class="line">早晚温差大，外出注意保暖。</span><br></pre></td></tr></table></figure>
<p>上面的内容是会话变量history，我们创建的时候，记得<font color="#ff0000">创建为str类型。变量赋值时，选择覆盖</font>。<br>这是代码节点的代码：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>(<span class="params">old_history: <span class="built_in">str</span>, user_query: <span class="built_in">str</span>, **kwargs</span>) -&gt; <span class="built_in">dict</span>:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    该函数用于格式化并存储对话历史，最多保留最近 5 轮对话。</span></span><br><span class="line"><span class="string">    :param old_history: 之前的对话历史字符串</span></span><br><span class="line"><span class="string">    :param user_query: 当前用户的提问</span></span><br><span class="line"><span class="string">    :param kwargs: 动态接收来自上游节点的回答（assistant 回答）</span></span><br><span class="line"><span class="string">    :return: 包含更新后历史记录的字典</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span>  </span><br><span class="line">    <span class="comment"># 1. 初始化当前回答</span></span><br><span class="line">    current_answer = <span class="string">&quot;&quot;</span>   </span><br><span class="line">    <span class="comment"># 2. 自动分拣：寻找那个“真正说话了”的分支（从上游变量中提取非空回答）</span></span><br><span class="line">    <span class="keyword">for</span> key, value <span class="keyword">in</span> kwargs.items():</span><br><span class="line">        <span class="keyword">if</span> value <span class="keyword">and</span> <span class="built_in">str</span>(value).strip() <span class="keyword">and</span> <span class="built_in">str</span>(value).lower() != <span class="string">&quot;none&quot;</span>:</span><br><span class="line">            current_answer = <span class="built_in">str</span>(value).strip()</span><br><span class="line">            <span class="keyword">break</span>          </span><br><span class="line">    <span class="comment"># 3. 空值保护：如果没找到任何回答或用户提问为空，原样返回旧账</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> current_answer <span class="keyword">or</span> <span class="keyword">not</span> user_query:</span><br><span class="line">        <span class="keyword">return</span> &#123;<span class="string">&quot;result&quot;</span>: old_history <span class="keyword">or</span> <span class="string">&quot;&quot;</span>&#125;</span><br><span class="line">    <span class="comment"># 4. 格式化当前轮次</span></span><br><span class="line">    <span class="comment"># 在 user 和 assistant 之间增加 \n\n，在对话块前后保持清晰界限</span></span><br><span class="line">    new_turn = <span class="string">f&quot;user: <span class="subst">&#123;user_query.strip()&#125;</span>\n\nassistant: <span class="subst">&#123;current_answer.strip()&#125;</span>&quot;</span></span><br><span class="line">    <span class="comment"># 5. 定义分隔符（用于区分每一轮对话）</span></span><br><span class="line">    separator = <span class="string">&quot;\n\n---\n\n&quot;</span></span><br><span class="line">    <span class="comment"># 6. 缝合逻辑</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> old_history <span class="keyword">or</span> <span class="keyword">not</span> <span class="built_in">str</span>(old_history).strip():</span><br><span class="line">        full_history = new_turn</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="comment"># 去掉旧历史末尾可能存在的空格或换行，再进行缝合</span></span><br><span class="line">        full_history = <span class="string">f&quot;<span class="subst">&#123;old_history.strip()&#125;</span><span class="subst">&#123;separator&#125;</span><span class="subst">&#123;new_turn&#125;</span>&quot;</span>   </span><br><span class="line">    <span class="comment"># 7. 截断逻辑：只保留最近 10 轮</span></span><br><span class="line">    <span class="comment"># 使用定义好的 separator 进行精准切割</span></span><br><span class="line">    history_list = full_history.split(separator)</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(history_list) &gt; <span class="number">10</span>:</span><br><span class="line">        <span class="comment"># 只取最后 10 个元素</span></span><br><span class="line">        history_list = history_list[-<span class="number">10</span>:]      </span><br><span class="line">    <span class="comment"># 8. 重新组装最终输出</span></span><br><span class="line">    final_output = separator.join(history_list)</span><br><span class="line">    <span class="comment"># 返回 Dify 要求的字典格式</span></span><br><span class="line">    <span class="keyword">return</span> &#123;</span><br><span class="line">        <span class="string">&quot;result&quot;</span>: final_output</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<p>关于对话内容这里，我们简单粗暴的采取了类似记忆节点的丢失策略，就是大于10的话，我们就会把原来的丢弃。主要是考虑到响应时间的问题。<br>在正式生产环境中，这个位置，我认为，应该搞一个记忆节点，采取压缩策略，而不是直接丢弃。将超过多少轮的对话，走一下记忆分支，进行压缩。<br>这样，我们就可以将所有的内容，都输入到query改写节点。<br><img src="https://wenhua-image.oss-cn-beijing.aliyuncs.com/%E5%BE%AE%E4%BF%A1%E5%85%AC%E4%BC%97%E5%8F%B7/query%E6%94%B9%E5%86%99%E8%8A%82%E7%82%B9%E9%85%8D%E7%BD%AE.png" alt="query改写节点配置"></p>
<p>这样，我们可以解决第一个问题，如何确保准确理解用户问题，确保改写正确。</p>
<h2 id="2-引入状态机，实现多轮对话"><a href="#2-引入状态机，实现多轮对话" class="headerlink" title="2. 引入状态机，实现多轮对话"></a>2. 引入状态机，实现多轮对话</h2><p>首先，大家不要被状态机这三个字吓到哈。<br>其实可以理解为我们有一个笔记本，上面记着我们需要做的事情（to do list），和做成这件事情所必须的东西（参数）。</p>
<p>按照上一代智能客服的分类来说，通常，我们将用户的问题分为以下几类：<br>FAQ、转人工、单轮任务、多轮任务、闲聊等。<br>FAQ用大模型来做，就是结合RAG知识库进行回答。<br>转人工就是智能客服解决不了，或者必须由人工客服完成的需求。<br>单轮任务，是类似用完即走的。比如银行领域，只要客户登录了，客户问一句，我的账户余额是多少。系统其实只需要校验登录态即可。校验完成，不需要其他任何信息就可以完成任务，直接回复答案。<br><img src="https://wenhua-image.oss-cn-beijing.aliyuncs.com/%E5%BE%AE%E4%BF%A1%E5%85%AC%E4%BC%97%E5%8F%B7/%E9%97%AE%E9%A2%98%E5%88%86%E7%B1%BB%E8%B7%AF%E7%94%B1%E8%A7%A3%E9%87%8A.png" alt="问题分类"><br>难度比较大的是多轮任务，因为多轮任务往往需要和客户确认很多信息。以查询天气为例，我们需要知道用户要查询哪里的天气以及时间。<br>在智能客服领域，大部分的客户来这里咨询基本都是1-3个主题，用完即走。但是也有部分客户，会咨询很多问题。所以就有可能出现下面的情况：</p>
<table>
<thead>
<tr>
<th><strong>轮次</strong></th>
<th><strong>用户输入</strong></th>
<th><strong>LLM（语义提取与意图映射）</strong></th>
<th><strong>状态机系统（数据结构维护）</strong></th>
</tr>
</thead>
<tbody><tr>
<td><strong>01</strong></td>
<td>“下周三我想从成都开车去拉萨。”</td>
<td><strong>映射任务：</strong> <code>路径规划</code> <strong>提取槽位：</strong> <code>from: 成都</code>, <code>to: 拉萨</code>, <code>date: 2026-01-28</code></td>
<td><strong>初始化：</strong> 创建 <code>task_id: 451425c2</code>，压入 <code>task_stack</code>。 <strong>锁逻辑：</strong> <code>global_intent_lock</code> 设置为 <strong>LOCKED</strong>。</td>
</tr>
<tr>
<td><strong>02</strong></td>
<td>“那边现在冷吗？推荐个保险吧。”</td>
<td><strong>映射任务：</strong> <code>投保咨询</code> <strong>提取槽位：</strong> <code>type: 旅游险</code> <strong>识别背景：</strong> 用户提及“冷”，关联高原环境。</td>
<td><strong>任务压栈：</strong> <code>task_stack</code> 顶部新增 <code>投保</code> 任务。当前 <code>current_task</code> 切换为保险。 <strong>状态记录：</strong> <code>stage</code> 设为 <strong>COLLECTING</strong>，此时 <code>slots</code> 中 <code>high_risk_confirm</code>（高风险确认）为 <code>null</code>。</td>
</tr>
<tr>
<td><strong>03</strong></td>
<td>“会有高原反应吗？保险管这个吗？”</td>
<td><strong>解析意图：</strong> 知识问答（FAQ） <strong>提取槽位：</strong> 无新槽位。</td>
<td><strong>中断处理：</strong> 系统识别到这是临时提问。状态机<strong>挂起</strong>当前投保任务，允许 LLM 回答 FAQ，但不改变 <code>current_task</code> 的任务 ID。</td>
</tr>
<tr>
<td><strong>04</strong></td>
<td>“行，那买一份吧。”</td>
<td><strong>解析意图：</strong> 确认投保。 <strong>LLM 局限：</strong> LLM 可能会直接跳到支付。</td>
<td><strong>逻辑拦截：</strong> 状态机检查 <code>current_task_slots</code>。发现“高风险运动确认”仍为 <code>null</code>。 <strong>强制执行：</strong> 状态机拒绝进入 <code>EXECUTING</code> 阶段，强制将 <code>stage</code> 保持在 <strong>COLLECTING</strong>，并指令回复“请确认是否包含攀登等高风险运动”。</td>
</tr>
<tr>
<td><strong>05</strong></td>
<td>“不去了，改去三亚，那边暖和。”</td>
<td><strong>解析意图：</strong> 全局意图变更。 <strong>提取槽位：</strong> <code>to: 三亚</code></td>
<td><strong>级联更新：</strong> 触发 <code>__updated_variables</code>。状态机清空栈内与“高原”相关的保险子任务。 <strong>恢复主任务：</strong> 重新定位到 <code>路径规划</code>，将 <code>to</code> 从拉萨改为三亚。</td>
</tr>
</tbody></table>
<p>所以就想我开头举的例子，用户的槽位信息一直在变动，所以全靠大模型来干，相对于写到代码或者用参数值来保存，在提示词中引用最新的槽位和任务状态来说，任务完成率肯定相对来说会有很大的提升。<br>因此我们引入状态机：<br><img src="https://wenhua-image.oss-cn-beijing.aliyuncs.com/%E5%BE%AE%E4%BF%A1%E5%85%AC%E4%BC%97%E5%8F%B7/%E7%8A%B6%E6%80%81%E6%9C%BAdify%E5%B7%A5%E4%BD%9C%E6%B5%81.png" alt="状态机dify工作流"></p>
<p>在这里，还是主要使用会话变量来进行参数及参数值的存储，使用代码节点来进行状态机的维护，使用变量赋值节点来进行会话变量的更新。<br>注意，我所有的变量在这里使用的都是str类型（字符串类型），本来想使用json，但是json有两个地方在dify里面不太好。一是json的属性不支持嵌套；二是json不支持直接在llm的提示词中引用。所以我统一使用了str。<br><img src="https://wenhua-image.oss-cn-beijing.aliyuncs.com/%E5%BE%AE%E4%BF%A1%E5%85%AC%E4%BC%97%E5%8F%B7/%E4%BC%9A%E8%AF%9D%E5%8F%98%E9%87%8F.png" alt="会话变量"></p>
<p><code>current_task_slots</code>是当前任务的词槽信息或者说，我收集的需要信息，才能去调用工具来进行查询。<br><code>current_task</code>是当前的任务。<br><code>sys_context_str</code>里面是全量的信息，包含了</p>
<table>
<thead>
<tr>
<th><strong>参数名称</strong></th>
<th><strong>角色</strong></th>
<th><strong>生活场景类比（理发店）</strong></th>
<th><strong>专业作用与案例</strong></th>
</tr>
</thead>
<tbody><tr>
<td><strong><code>global_intent_lock</code></strong></td>
<td><strong>状态锁 &#x2F; 忙碌指示灯</strong></td>
<td><strong>理发师工位上的“正在服务&#x2F;空闲”指示牌</strong></td>
<td><strong>作用：</strong> 这是一个全局标记，用来告诉系统当前是否“被占用”。<br><br>  <br><br>防止在处理复杂任务时，被用户的随意插话打断核心流程。<br><br>  <br>  <br><br><strong>案例：</strong> 值是 <code>LOCKED</code>（红灯），表示Tony老师正在剪发，暂时不接新客；值是 <code>UNLOCKED</code>（绿灯），表示随时可以接单。</td>
</tr>
<tr>
<td><strong><code>current_task_id</code></strong></td>
<td><strong>当前任务ID &#x2F; 流水号</strong></td>
<td><strong>理发师手里拿着的那张“排队号小票”</strong></td>
<td><strong>作用：</strong> 唯一标识当前正在处理的那一个任务，用于系统追踪和日志记录。<br><br>  <br><br>不管你在任务栈里压了多少事，系统只认这一串ID作为当前焦点。<br><br>  <br>  <br><br><strong>案例：</strong> 比如 <code>a1b2c3d4</code>。如果系统报错，工程师可以通过这个ID在后台查到这笔“订单”的所有操作记录。</td>
</tr>
<tr>
<td><strong><code>task_stack</code></strong></td>
<td><strong>记忆栈 &#x2F; 待办事项清单</strong></td>
<td><strong>前台板夹上夹着的一叠“服务单”</strong></td>
<td><strong>作用：</strong> 这是<strong>多轮对话的灵魂</strong>。它是一个列表（List），按顺序记录了用户未完成的所有需求。采用“后进先出”原则，最后进来的需求最先处理。<br><br>  <br>  <br><br><strong>案例：</strong><br><br>  <br><br>1. 底层单子：查天气（暂挂起）<br><br>  <br><br>2. 顶层单子：查路线（正在做）<br><br>  <br><br>当查路线做完后，这张单子被撕掉，理发师就会看到下面那张“查天气”的单子，继续服务。</td>
</tr>
<tr>
<td><strong><code>slots</code></strong><br><br>  <br><br><em>(位于 task_stack 内部)</em></td>
<td><strong>槽位信息 &#x2F; 需求填空表</strong></td>
<td>服务单上具体的勾选栏：<br><br>  <br><br>“洗剪吹？染发？什么颜色？”</td>
<td><strong>作用：</strong> 具体的业务数据容器。机器人多轮追问的过程，本质上就是为了把这些空填满。<br><br>  <br>  <br><br><strong>案例：</strong><br><br>  <br><br>在“查天气”的任务里，<code>slots</code> 就是一张表：<br><br>  <br><br><code>&#123; city: &quot;北京&quot;, date: null &#125;</code>。<br><br>  <br><br>因为 <code>date</code> 是空，机器人下一句就会问：“请问您要查哪一天的？”</td>
</tr>
<tr>
<td><strong><code>stage</code></strong><br><br>  <br><br><em>(位于 task_stack 内部)</em></td>
<td><strong>任务阶段 &#x2F; 进度条</strong></td>
<td>服务单上的印章状态：<br><br>  <br><br>“待服务”、“进行中”、“已完结”</td>
<td><strong>作用：</strong> 控制任务的生命周期。只有标记为 <code>DONE</code> 的任务才会被系统清理掉。<br><br>  <br>  <br><br><strong>案例：</strong><br><br>  <br><br><code>COLLECTING</code>：还在问用户要信息（剪发中）。<br><br>  <br><br><code>DONE</code>：信息收齐了，可以给结果了（剪完洗头送客）。</td>
</tr>
<tr>
<td>看起来还是很复杂哈，不知道有没有把大家给劝退了。我们一步步拆解一下。</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td><img src="https://wenhua-image.oss-cn-beijing.aliyuncs.com/%E5%BE%AE%E4%BF%A1%E5%85%AC%E4%BC%97%E5%8F%B7/sys_context_str.png" alt="状态机核心"></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>用户输入一个问题，我需要结合历史的对话信息对这个问题进行改写，这样呢，就变相的实现了llm的记忆。接下来，按照思路，我们肯定需要一个路由，来区分用户的问题到底是分给谁来处理，用户的问题是一个FAQ？一个单轮任务？还是要求转人工呢？</td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody></table>
<p>所以我们就有了这样的工作流的开头：<br><img src="https://wenhua-image.oss-cn-beijing.aliyuncs.com/%E5%BE%AE%E4%BF%A1%E5%85%AC%E4%BC%97%E5%8F%B7/%E9%97%AE%E9%A2%98%E5%88%86%E7%B1%BB%E8%B7%AF%E7%94%B1.png" alt="问题分类及路由"></p>
<p>很好，现在我们知道用户这次想要做什么了，知道该给谁了，但是我们刚刚搞了一个笔记本，所以这里就要抓紧去维护一下笔记本的状态。但是大家也看到了刚刚的笔记本结构比较复杂，我们不能用简单的变量追加、覆盖处理。所以我们需要使用一个代码节点来做这个事情。代码节点，更新完笔记的内容，我们要写下来，所以需要变量赋值节点赋值给会话变量。<br><img src="https://wenhua-image.oss-cn-beijing.aliyuncs.com/%E5%BE%AE%E4%BF%A1%E5%85%AC%E4%BC%97%E5%8F%B7/%E5%A6%82%E4%BD%95%E7%BB%B4%E6%8A%A4%E7%8A%B6%E6%80%81%E6%9C%BA.png" alt="代码节点维护状态机"><br><img src="https://wenhua-image.oss-cn-beijing.aliyuncs.com/%E5%BE%AE%E4%BF%A1%E5%85%AC%E4%BC%97%E5%8F%B7/%E7%8A%B6%E6%80%81%E6%9C%BA%E6%A0%B8%E5%BF%83%E7%AE%A1%E7%90%86.png" alt="状态机核心管理"></p>
<p>ok，至此，其实本次多轮对话的核心升级就完成了。下面都是为了逻辑更加流畅。<br>因为代码节点的代码比较长，所以这里我就不贴出来了。大家如有兴趣，请在评论区留言，我会提供代码或者DSL。</p>
<p>接下来，我们判断是不是多轮对话，如果不是，就直接进入最终的判断分支进行了路由，如果是，那就需要进行信息提取节点。</p>
<p><img src="https://wenhua-image.oss-cn-beijing.aliyuncs.com/%E5%BE%AE%E4%BF%A1%E5%85%AC%E4%BC%97%E5%8F%B7/%E4%BF%A1%E6%81%AF%E6%8F%90%E5%8F%96%E5%8F%8A%E8%BF%BD%E9%97%AE.png" alt="多轮任务信息提取详解"><br>词槽不全就追问客户。<br><img src="https://wenhua-image.oss-cn-beijing.aliyuncs.com/%E5%BE%AE%E4%BF%A1%E5%85%AC%E4%BC%97%E5%8F%B7/%E6%99%BA%E8%83%BD%E8%BF%BD%E9%97%AE.png" alt="追问词槽"><br>追问节点的提示词写的也比较简单，主要是想要验证想法，供大家参考：</p>
<figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line"><span class="section"># Role</span></span><br><span class="line">你是一个专业的对话意图澄清助手。你的工作是根据当前的任务状态和已收集的信息，判断还缺少哪些关键信息，并向用户发起追问。</span><br><span class="line"><span class="section"># Context</span></span><br><span class="line">用户正在进行一项多轮对话任务，系统维护了一个“状态机”来记录任务进度。</span><br><span class="line"><span class="section"># Goal</span></span><br><span class="line">请检查 <span class="code">`task_slots`</span> 中 value 为 <span class="code">`null`</span> 或 <span class="code">`None`</span> 或 空字符串 的字段。</span><br><span class="line">生成一句简短、自然、礼貌的追问，引导用户补充这些缺失的信息。</span><br><span class="line"><span class="section"># Constraints</span></span><br><span class="line"><span class="bullet">1.</span> <span class="strong">**只追问缺失项**</span>：不要提及已经填好的项，除非为了确认上下文（例如“好的，关于北京的天气，请问是哪一天？”）。</span><br><span class="line"><span class="bullet">2.</span> <span class="strong">**一次问一个**</span>：如果缺多个槽位，优先追问逻辑上最靠前或最重要的一个，不要一次性甩出一堆问题，保持对话的交互感。</span><br><span class="line"><span class="bullet">3.</span> <span class="strong">**口语化**</span>：不要使用“请输入参数 city”这种技术语言，要说“请问您想查询哪个城市？”。</span><br><span class="line"><span class="bullet">4.</span> <span class="strong">**输出格式**</span>：直接输出追问的话术，不要包含任何 JSON、Markdown 标记或额外解释。</span><br><span class="line"><span class="section"># Examples</span></span><br><span class="line"><span class="section">## Example 1</span></span><br><span class="line">Input:</span><br><span class="line">Task: 查询天气</span><br><span class="line">Slots: &#123;&quot;city&quot;: &quot;上海&quot;, &quot;date&quot;: null&#125;</span><br><span class="line"></span><br><span class="line">Output:</span><br><span class="line">没问题，请问您想查询上海哪一天的天气呢？</span><br><span class="line"></span><br><span class="line"><span class="section">## Example 2</span></span><br><span class="line">Input:</span><br><span class="line">Task: 查询路线</span><br><span class="line">Slots: &#123;&quot;origin&quot;: null, &quot;destination&quot;: &quot;北京西站&quot;&#125;</span><br><span class="line"></span><br><span class="line">Output:</span><br><span class="line">收到，那您的出发地是哪里？</span><br><span class="line"></span><br><span class="line"><span class="section">## Example 3</span></span><br><span class="line">Input:</span><br><span class="line">Task: 预订会议室</span><br><span class="line">Slots: &#123;&quot;time&quot;: null, &quot;people&quot;: null&#125;</span><br><span class="line"></span><br><span class="line">Output:</span><br><span class="line">好的，请问您计划在这个会议室开会的时间大概是几点？</span><br></pre></td></tr></table></figure>
<p>如果路由到FAQ，那我们就检索知识库；路由到单轮任务，我们就直接调用api回答用户。<br><img src="https://wenhua-image.oss-cn-beijing.aliyuncs.com/%E5%BE%AE%E4%BF%A1%E5%85%AC%E4%BC%97%E5%8F%B7/%E8%B7%AF%E7%94%B1%E5%AE%8C%E6%88%90%E4%BB%BB%E5%8A%A1.png" alt="完成任务"><br>因为主要是为了模拟，所以agent节点的配置就特别简单，我没有设置很复杂的提示词。<br><img src="https://wenhua-image.oss-cn-beijing.aliyuncs.com/%E5%BE%AE%E4%BF%A1%E5%85%AC%E4%BC%97%E5%8F%B7/agent%E8%8A%82%E7%82%B9.png" alt="agent节点"><br>最终实现的效果：<br><img src="https://wenhua-image.oss-cn-beijing.aliyuncs.com/%E5%BE%AE%E4%BF%A1%E5%85%AC%E4%BC%97%E5%8F%B7/%E6%95%88%E6%9E%9C.png" alt="多轮对话"><br><img src="https://wenhua-image.oss-cn-beijing.aliyuncs.com/%E5%BE%AE%E4%BF%A1%E5%85%AC%E4%BC%97%E5%8F%B7/%E5%A4%9A%E6%84%8F%E5%9B%BE%E6%9C%AA%E5%A4%84%E7%90%86.png" alt="多意图未处理"></p>
<p>综合下来，我们的这个新的工作流的整体思路其实就是这个样子：<br><img src="https://wenhua-image.oss-cn-beijing.aliyuncs.com/%E5%BE%AE%E4%BF%A1%E5%85%AC%E4%BC%97%E5%8F%B7/%E5%A4%9A%E8%BD%AE%E5%AF%B9%E8%AF%9D%E5%B7%A5%E4%BD%9C%E6%B5%81%E9%80%BB%E8%BE%91.png" alt="多轮对话完整工作流"></p>
<h2 id="3-小结"><a href="#3-小结" class="headerlink" title="3. 小结"></a>3. 小结</h2><p>上面说的内容，可能没有第一次那么细，但是主体思路应该是讲明白了。<br><strong>使用状态机，对会话状态进行管理</strong>。<br>使用了多个LLM节点，<strong>完成不同的任务，让他们专注于自己的任务</strong>，从而提高成功率。</p>
<p>这个版本仍然有很多的问题，但是主体结构已经完成了。还<strong>需要解决的问题如下</strong>：</p>
<ol>
<li>响应时间比较长（LLM节点太多了）</li>
<li>每个节点没有做异常分支处理。例如什么时候转人工。</li>
<li>对最终的回答，没有进行内容审核，确保不生成不合规内容。</li>
<li>没有对多意图进行处理，比如一句话有两个多轮任务。</li>
<li>没有做详细的测试，设置任务成功率、拒识率、转人工率、一次性完成率、准确率等指标的相关统计及测试优化。<br><img src="https://wenhua-image.oss-cn-beijing.aliyuncs.com/%E5%BE%AE%E4%BF%A1%E5%85%AC%E4%BC%97%E5%8F%B7/%E5%BE%85%E4%BC%98%E5%8C%96%E7%9A%84%E9%97%AE%E9%A2%98.png" alt="方案待优化的问题"></li>
</ol>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a href="https://www.wenhuateng.top">华子</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a href="https://www.wenhuateng.top/posts/6066dc27/">https://www.wenhuateng.top/posts/6066dc27/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来源 <a href="https://www.wenhuateng.top" target="_blank">吏部侍郎</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/Dify/">Dify</a><a class="post-meta__tags" href="/tags/Agent/">Agent</a><a class="post-meta__tags" href="/tags/LLM/">LLM</a></div><div class="post-share"><div class="social-share" data-image="https://wenhua-image.oss-cn-beijing.aliyuncs.com/%E5%BE%AE%E4%BF%A1%E5%85%AC%E4%BC%97%E5%8F%B7/%E5%B0%81%E9%9D%A2%E5%9B%BE.png" data-sites="wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><a class="pagination-related" href="/posts/c1c71f62/" title="遇事不决问AI的含金量：看我如何一句话把Python脚本打包成EXE"><img class="cover" src="https://wenhua-image.oss-cn-beijing.aliyuncs.com/%E5%BE%AE%E4%BF%A1%E5%85%AC%E4%BC%97%E5%8F%B7/%E6%96%87%E7%AB%A0%E5%B0%81%E9%9D%A2%E5%9B%BE.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="info"><div class="info-1"><div class="info-item-1">上一篇</div><div class="info-item-2">遇事不决问AI的含金量：看我如何一句话把Python脚本打包成EXE</div></div><div class="info-2"><div class="info-item-1">给业务人员（比如家里那位）写Python脚本，最头疼的往往不是代码本身，而是交付。 你让人家装Python、配pip、安依赖包，这事儿基本就黄了。最好的交付方式，永远是给对方一个双击就能用的 .exe 文件。 但是，我完全不知道行不行的通，行得通的话，应该怎么做。 遇事不决，可问AI。  于是，我就问AI能不能把python环境，python包统一打包成一个exe应用，直接点击就能使用。  果然可以。 然后我就开始使用trae（字节跳动的AI写代码的软件），来帮我打包。 命令很简单： 使用PyInstaller将当前目录下的python脚本打包为直接点击即可使用，无需配置各种环境的exe应用  ok，一次成功。  既然流程跑通了，这事儿我也不会只做一次，我就寻思得把这次成功的“过程”固化下来，变成可复用的资产。 所以我进一步搞了一个 Skill（技能）。你可以理解为我给AI写了一份“标准作业程序（SOP）”。 只要有具体的操作步骤，就可以搞成skill。 继续使用trae创建： 使用skill-creater，将 `https://github.com/pyinstaller/p...</div></div></div></a><a class="pagination-related" href="/posts/65123a1c/" title="生产级写提示词的一些小的tips"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-right"><div class="info-1"><div class="info-item-1">下一篇</div><div class="info-item-2">生产级写提示词的一些小的tips</div></div><div class="info-2"><div class="info-item-1">1、提示词正常来说有两种方式：一种是结合xml格式，例如：这是一份客服质检数据 一种是markdown结构，例如：## 背景   这是一份客服质检数据。 很多人有习惯让AI来帮我们写提示词，我也会这样做。这里有个建议，去掉AI生成的提示词中的大量的**，之类的东西。这些会占用大量的token，浪费钱，这些符号仅仅只是让我们在markdown渲染工具里面看起来更舒服而已，对大模型来说无所谓的。我们用markdown或者xml是为了结构化，而不是复杂化。 2、生产级任务中，可以写一些示例，我们知道，大模型是非常擅长模仿的，但更适合用在你期望输出结果相对稳定、格式明确的情况。示例要结合各种情况进行应用。比如，你在每天的固定时间，系统要去固定查询一些数据，然后帮你生成一个邮件（html）。这种情况你期望的是一个极其相似的结果。那你就可以给个html模板或者html邮件示例。当然html示例可能会很长，这个时候就别让模型生成了，写一个脚本，在这个节点接收模型产生的数据，直接将数据由脚本渲染为html（可以让AI来写，但是要调试）。 当然，或者是，编写产品需求说明文档（PRD），每个公司肯定...</div></div></div></a></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><a class="pagination-related" href="/posts/41bc2162/" title="保险代理人必备技能？一键生成走心又专业的客户生日祝福网页！"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-04-04</div><div class="info-item-2">保险代理人必备技能？一键生成走心又专业的客户生日祝福网页！</div></div><div class="info-2"><div class="info-item-1">需求背景：保后管理部，会每天人工统计及整理C-M1数据，入账及回盘相关的数据，最后汇总整理相关话术，发送到微信群。于是咨询我能不能使用Deepseek等大模型实现。前两天，我正在用大模型，于是肯定的回复，是可以的。今天又在开源平台dify上实验了下，也顺利成功。 这里我以一个考勤小助手为例，给大家演示一下搭建步骤。 首先，本文主要用的工具如下：  Dify(一个开源的Agent编排平台)企业微信LLM：Deepseek-V3-0324  1. 新建应用+安装企微通知工具1.1新建空白应用&amp;实现逻辑梳理打开https://dify.ai/zh，选择开始使用。进行注册和登录。创建空白应用—选择工作流。首先思考下整体会用到哪些节点。  我们是考勤小助手，因此肯定会用到考勤相关的规章制度，需要一个知识库。 还需要一个LLM节点来进行格式整理。 需要一个企微的通知节点。  1.2 安装企微通知工具选择添加节点——工具。搜索企微通知工具，输入wecom。最后进行安装。安装完成以后，记得刷新下页面，不然找不到这个企微通知工具。 2. 搭建考勤小助手因为在这里我演示的是一个考勤小助手，因...</div></div></div></a><a class="pagination-related" href="/posts/f3860a0a/" title="Dify官方没给的“触发器”，我用一个Webhook异步技巧“曲线救国”了"><img class="cover" src="https://wenhua-image.oss-cn-beijing.aliyuncs.com/%E5%BE%AE%E4%BF%A1%E5%85%AC%E4%BC%97%E5%8F%B7/Dify%E5%AE%98%E6%96%B9%E6%B2%A1%E7%BB%99%E7%9A%84%E2%80%9C%E8%A7%A6%E5%8F%91%E5%99%A8%E2%80%9D%EF%BC%8C%E6%88%91%E7%94%A8%E4%B8%80%E4%B8%AAWebhook%E5%BC%82%E6%AD%A5%E6%8A%80%E5%B7%A7%E2%80%9C%E6%9B%B2%E7%BA%BF%E6%95%91%E5%9B%BD%E2%80%9D%E4%BA%86.jpeg" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-10-26</div><div class="info-item-2">Dify官方没给的“触发器”，我用一个Webhook异步技巧“曲线救国”了</div></div><div class="info-2"><div class="info-item-1"> 不知道大家怎么落地大模型的。我现在完全都是从小事出发，因为搞业务，业务难搞。所以先把自己解放出来。 就比如，我比较烦一件事情，每次流程要求，需求评审之前必须发需求评审邮件，我挺烦这件事情，虽然那内容不复杂，但是每次都要自己写，从需求管理平台里面复制名字，链接，还要写评审时间，按照格式填充邮件模板，然后找抄送人发送人。 我就寻思让大模型给我干了。但是大模型又不知道我是什么需求，每次我给他打出来，那还不是很复杂吗。没必要啊。 所以就有了今天这个事儿。 我就用Dify搞了一下。 当然，自己解放出来就有更多时间思考业务，就比如这次这个事儿，完全可以复用用在很多其他场景，比如我要到时间了自动给客户发送一个个性的生日祝福，每次开发个http请求，调用官方api多麻烦啊。 dify又没有触发器，那还能咋整，我们自己想办法呗。 还有个点就是，我是真服了。网上那么多教程啊，文档啊，那都是给懂技术的老师写的，像我们这种，那是真难啊，要是没了AI，我想搞成这个事儿那是不可能的。 不多说废话了，我们开始哈。 这个文章有点长，我想记录下这个插件的使用方式，配置项是怎么用的，一个方式方便自己记录，另一个是...</div></div></div></a><a class="pagination-related" href="/posts/db1bad86/" title="Dify知识库图文混排到底应该怎么做，两种主流方案，一次讲清！"><img class="cover" src="https://wenhua-image.oss-cn-beijing.aliyuncs.com/%E5%BE%AE%E4%BF%A1%E5%85%AC%E4%BC%97%E5%8F%B7/%E5%B0%81%E9%9D%A2%E5%9B%BE1.jpg" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-11-16</div><div class="info-item-2">Dify知识库图文混排到底应该怎么做，两种主流方案，一次讲清！</div></div><div class="info-2"><div class="info-item-1"> 如果你想在使用dify知识库的实现下面的图文混排效果，那你非常有必要读一下这篇文章。  我发现，目前实现这样的图文混排效果应该是有两种方案： 使用图床或者直接将word文件导入知识库。 大家用知识库多的话，或者大模型多的话，可能都知道大模型其实非常擅长理解markdown文件，图床就是markdown中的图像在网络上存储的位置。 而word导入知识库以后，word中的图片会被dify的知识库解析，然后存储到dify所在的服务器。 上面的这两种方案，其实本质上的原理，都是使用的dify的前端是支持markdown渲染的。因此，markdown的图片渲染也是支持的。 下面实验的dify版本是1.9.2，win11环境，docker启动。 markdown图床使用markdown图床的方式，实现知识库答案的图文混排。 前几天，我们怕了E大很多的文章，这里我们就以E大的文章为例。 如果大家看了之前的文章的话： 从被 Trae 气到崩溃，到用 Gemini 一次跑通，终于爬下了孟岩和E大的全部理财干货 可能看到了我爬取得markdown文档图片是在本地电脑上存储的，在markdown中的...</div></div></div></a><a class="pagination-related" href="/posts/7e3d8aea/" title="在Dify工作流里，我为什么“剥夺”了大模型调用工具的能力？"><img class="cover" src="https://wenhua-image.oss-cn-beijing.aliyuncs.com/%E5%BE%AE%E4%BF%A1%E5%85%AC%E4%BC%97%E5%8F%B7/%E5%9C%A8Dify%E5%B7%A5%E4%BD%9C%E6%B5%81%E9%87%8C%EF%BC%8C%E6%88%91%E4%B8%BA%E4%BB%80%E4%B9%88%E2%80%9C%E5%89%A5%E5%A4%BA%E2%80%9D%E4%BA%86%E5%A4%A7%E6%A8%A1%E5%9E%8B%E8%B0%83%E7%94%A8%E5%B7%A5%E5%85%B7%E7%9A%84%E8%83%BD%E5%8A%9B%EF%BC%9F--%E5%B0%81%E9%9D%A22.jpeg" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-10-29</div><div class="info-item-2">在Dify工作流里，我为什么“剥夺”了大模型调用工具的能力？</div></div><div class="info-2"><div class="info-item-1"> 在生产环境用 Dify，我们最头疼的就是大模型的不确定性。 让 Agent 节点自己调用工具，结果总会有点飘。 今天分享一个能让工作流更稳定、更可控的小技巧： 就是我们可以将MCP中的工具作为工具节点直接插入dify的工作流中。 不知道大家有没有注意到我上一篇文章的一个使用方式：  这里我直接将腾讯的Edgeone-Pages当做一个工具节点了。大家可以看到它是一个工具，这个实际上是我从dify的插件市场下载的一个工具插件，最主要是这玩意儿必须要申请APIkey.而且它输出的text不是url，还需要我从json中提取，所以我加了一个模板转换节点。 虽然他的apikey申请起来并不是特别费劲。 但是大家如果之前在其他地方用过腾讯这个网页部署的mcp服务的话，应该是知道，他是不需要key的。  所以，比如我们可以直接登录modelscope（魔塔社区），开通一下这个服务。 魔塔社区EdgeOne Pages · MCP  然后配置到你的dify里面：  接下来，我们就可以直接再工作流里面把MCP中的工具，直接当做工具引用了。  大家看下效果：  当然，这只是非常简短的一个案例。 ...</div></div></div></a><a class="pagination-related" href="/posts/e62a5405/" title="你的 RAG 还在“垃圾进，垃圾出”？我用这套流程，把“废料”文档变成了黄金知识库"><img class="cover" src="https://wenhua-image.oss-cn-beijing.aliyuncs.com/%E5%BE%AE%E4%BF%A1%E5%85%AC%E4%BC%97%E5%8F%B7/%E4%BD%A0%E7%9A%84RAG%E8%BF%98%E5%9C%A8%E5%9E%83%E5%9C%BE%E8%BF%9B%E5%9E%83%E5%9C%BE%E5%87%BA.jpeg" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-09-09</div><div class="info-item-2">你的 RAG 还在“垃圾进，垃圾出”？我用这套流程，把“废料”文档变成了黄金知识库</div></div><div class="info-2"><div class="info-item-1"> 最近大家关注Dify的进展的话，应该知道它的版本更新直接从1.8.0—&gt;2.0.1了。跨越了一个大的版本。它本次的主要更新就在于知识库构建的知识流水线。 我认为Dify2.0以后的知识流水线会极大地降低了构建知识库的门槛，未来也许能高效处理 80% 的相对标准的文档。 但是，仍然会有20%，还是要依赖于我们人来手动处理。 我们都知道，现阶段来说，对于知识库，仍然是一个垃圾进垃圾出的状态，因此，在构建知识库之前我们需要对知识文档做很多的预处理。 今天这篇文章的分享，其实也是想给大家分享下我们自己手工处理文档的数据清洗思路。  1. RAG知识库的瓶颈知识库的质量不取决于模型，而取决于“垃圾进，垃圾出”的铁律。真正的瓶颈是ETL（抽取、转换、加载）过程，尤其是从非结构化源文档到结构化知识块（Chunks）的转换过程。 我们每个公司其实私有的数据量，私有的文档是非常庞大的，而它的内容又是千奇百怪的。针对一个合同，就可能有几十几百种格式，所以指望一套流程来完成这个非结构化源文档到RAG知识库的转变基本是不可能的。 我们如果想偷懒直接将某个文档上传到RAG知识库，就希望他回答的10...</div></div></div></a><a class="pagination-related" href="/posts/2c813f5f/" title="保姆级教程：手把手教你用Dify实现完美多轮对话（附Chatflow和提示词）"><img class="cover" src="https://wenhua-image.oss-cn-beijing.aliyuncs.com/%E5%BE%AE%E4%BF%A1%E5%85%AC%E4%BC%97%E5%8F%B7/%E5%B0%81%E9%9D%A2%E5%9B%BE4.jpeg" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-08-09</div><div class="info-item-2">保姆级教程：手把手教你用Dify实现完美多轮对话（附Chatflow和提示词）</div></div><div class="info-2"><div class="info-item-1">在这篇文章里，我想和大家分享一下我是如何一步步建立一个问答助手Demo的经历。过程中遇到了一些挑战，但同时也找到了解决办法，希望能给正在尝试类似项目的朋友们带来一点帮助和启发。  关键词：Dify 智能助手 记忆 多轮问答  1. 初版Demo创建应用首先，我们打开Dify，选择创建空白应用，随意取一个名字，创建一个chatflow。  创建应用后，打开界面如下，则直接就是  开始—–&gt;大模型——&gt;直接回复。   按照常规思路，很显现，现在需要一个知识库，比如用于回答公司内部的政策。所以我们需要加一个知识库节点。   ok，现在按照顺序，明显我们需要开始准备知识库了。 知识库的简单说明_一个问答助手，能不能准确的回复用户的问题，主要在于3个方面_：  知识库是不是构建的相对比较好，比如分块逻辑，块大小，检索逻辑等等。 LLM节点的提示词写的是不是足够好，足够稳定。 是不是很好的能理解用户的问题。  首先，构建知识库的时候，不要寄希望于丢几个 PDF 给嵌入模型，就可以有很好的效果。 比如我有一个PDF文件，我先实验了一下直接导入行不行，选择知识库—新建知识库—选择上传...</div></div></div></a></div></div><hr class="custom-hr"/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div class="vcomment" id="vcomment"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info text-center"><div class="avatar-img"><img src="/images/Happy.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info-name">华子</div><div class="author-info-description">一个懂业务的AI产品经理</div><div class="site-data"><a href="/archives/"><div class="headline">文章</div><div class="length-num">53</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">41</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">16</div></a></div><div class="card-info-social-icons"><a class="social-icon" href="https://github.com/Wangshixiong" target="_blank" title="Github"><i class="fab fa-github" style="color: #24292e;"></i></a><a class="social-icon" href="https://wenhua-image.oss-cn-beijing.aliyuncs.com/%E5%BE%AE%E4%BF%A1%E5%85%AC%E4%BC%97%E5%8F%B7/wechat.jpg" target="_blank" title="微信"><i class="fab fa-weixin" style="color: #07c160;"></i></a></div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content is-expand"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-%E4%BC%98%E5%8C%96%E9%97%AE%E9%A2%98%E6%94%B9%E5%86%99%E8%8A%82%E7%82%B9"><span class="toc-number">1.</span> <span class="toc-text">1. 优化问题改写节点</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-%E5%BC%95%E5%85%A5%E7%8A%B6%E6%80%81%E6%9C%BA%EF%BC%8C%E5%AE%9E%E7%8E%B0%E5%A4%9A%E8%BD%AE%E5%AF%B9%E8%AF%9D"><span class="toc-number">2.</span> <span class="toc-text">2. 引入状态机，实现多轮对话</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-%E5%B0%8F%E7%BB%93"><span class="toc-number">3.</span> <span class="toc-text">3. 小结</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/posts/c1c71f62/" title="遇事不决问AI的含金量：看我如何一句话把Python脚本打包成EXE"><img src="https://wenhua-image.oss-cn-beijing.aliyuncs.com/%E5%BE%AE%E4%BF%A1%E5%85%AC%E4%BC%97%E5%8F%B7/%E6%96%87%E7%AB%A0%E5%B0%81%E9%9D%A2%E5%9B%BE.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="遇事不决问AI的含金量：看我如何一句话把Python脚本打包成EXE"/></a><div class="content"><a class="title" href="/posts/c1c71f62/" title="遇事不决问AI的含金量：看我如何一句话把Python脚本打包成EXE">遇事不决问AI的含金量：看我如何一句话把Python脚本打包成EXE</a><time datetime="2026-01-23T13:00:00.000Z" title="发表于 2026-01-23 21:00:00">2026-01-23</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/posts/6066dc27/" title="进阶教程：给AI装上&quot;逻辑大脑&quot;，打造金融级稳定的多轮对话Agent（Dify实战）"><img src="https://wenhua-image.oss-cn-beijing.aliyuncs.com/%E5%BE%AE%E4%BF%A1%E5%85%AC%E4%BC%97%E5%8F%B7/%E5%B0%81%E9%9D%A2%E5%9B%BE.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="进阶教程：给AI装上&quot;逻辑大脑&quot;，打造金融级稳定的多轮对话Agent（Dify实战）"/></a><div class="content"><a class="title" href="/posts/6066dc27/" title="进阶教程：给AI装上&quot;逻辑大脑&quot;，打造金融级稳定的多轮对话Agent（Dify实战）">进阶教程：给AI装上&quot;逻辑大脑&quot;，打造金融级稳定的多轮对话Agent（Dify实战）</a><time datetime="2026-01-21T14:21:51.000Z" title="发表于 2026-01-21 22:21:51">2026-01-21</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/posts/65123a1c/" title="生产级写提示词的一些小的tips">生产级写提示词的一些小的tips</a><time datetime="2026-01-15T02:30:00.000Z" title="发表于 2026-01-15 10:30:00">2026-01-15</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/posts/1b26e8ea/" title="我只是想留住一个投资人的思考，结果学会了如何让 AI 替我干脏活"><img src="https://wenhua-image.oss-cn-beijing.aliyuncs.com/%E5%BE%AE%E4%BF%A1%E5%85%AC%E4%BC%97%E5%8F%B7/image-20260107002859783.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="我只是想留住一个投资人的思考，结果学会了如何让 AI 替我干脏活"/></a><div class="content"><a class="title" href="/posts/1b26e8ea/" title="我只是想留住一个投资人的思考，结果学会了如何让 AI 替我干脏活">我只是想留住一个投资人的思考，结果学会了如何让 AI 替我干脏活</a><time datetime="2026-01-06T13:56:00.000Z" title="发表于 2026-01-06 21:56:00">2026-01-06</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/posts/65084fb8/" title="Claude Code斜杠命令进阶：从自动化提交到智能分支管理"><img src="https://images.unsplash.com/photo-1617791160505-6f00504e3519" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Claude Code斜杠命令进阶：从自动化提交到智能分支管理"/></a><div class="content"><a class="title" href="/posts/65084fb8/" title="Claude Code斜杠命令进阶：从自动化提交到智能分支管理">Claude Code斜杠命令进阶：从自动化提交到智能分支管理</a><time datetime="2026-01-03T04:30:45.000Z" title="发表于 2026-01-03 12:30:45">2026-01-03</time></div></div></div></div></div></div></main><footer id="footer"><div class="footer-other"><div class="footer-copyright"><span class="copyright">&copy;&nbsp;2025 - 2026 By 华子</span><span class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo 7.3.0</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly 5.5.0</a></span></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="translateLink" type="button" title="简繁转换">2</button><button id="darkmode" type="button" title="日间和夜间模式切换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="前往评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.umd.min.js"></script><div class="js-pjax"><script>(() => {
  const runMermaid = ele => {
    window.loadMermaid = true
    const theme = document.documentElement.getAttribute('data-theme') === 'dark' ? 'dark' : 'default'

    ele.forEach((item, index) => {
      const mermaidSrc = item.firstElementChild
      const mermaidThemeConfig = `%%{init:{ 'theme':'${theme}'}}%%\n`
      const mermaidID = `mermaid-${index}`
      const mermaidDefinition = mermaidThemeConfig + mermaidSrc.textContent

      const renderFn = mermaid.render(mermaidID, mermaidDefinition)
      const renderMermaid = svg => {
        mermaidSrc.insertAdjacentHTML('afterend', svg)
      }

      // mermaid v9 and v10 compatibility
      typeof renderFn === 'string' ? renderMermaid(renderFn) : renderFn.then(({ svg }) => renderMermaid(svg))
    })
  }

  const codeToMermaid = () => {
    const codeMermaidEle = document.querySelectorAll('pre > code.mermaid')
    if (codeMermaidEle.length === 0) return

    codeMermaidEle.forEach(ele => {
      const preEle = document.createElement('pre')
      preEle.className = 'mermaid-src'
      preEle.hidden = true
      preEle.textContent = ele.textContent
      const newEle = document.createElement('div')
      newEle.className = 'mermaid-wrap'
      newEle.appendChild(preEle)
      ele.parentNode.replaceWith(newEle)
    })
  }

  const loadMermaid = () => {
    if (false) codeToMermaid()
    const $mermaid = document.querySelectorAll('#article-container .mermaid-wrap')
    if ($mermaid.length === 0) return

    const runMermaidFn = () => runMermaid($mermaid)
    btf.addGlobalFn('themeChange', runMermaidFn, 'mermaid')
    window.loadMermaid ? runMermaidFn() : btf.getScript('https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js').then(runMermaidFn)
  }

  btf.addGlobalFn('encrypt', loadMermaid, 'mermaid')
  window.pjax ? loadMermaid() : document.addEventListener('DOMContentLoaded', loadMermaid)
})()</script><script>(() => {
  const isShuoshuo = GLOBAL_CONFIG_SITE.pageType === 'shuoshuo'
  const option = null

  const initValine = (el, path) => {
    if (isShuoshuo) {
      window.shuoshuoComment.destroyValine = () => {
        if (el.children.length) {
          el.innerHTML = ''
          el.classList.add('no-comment')
        }
      }
    }

    const valineConfig = {
      el: '#vcomment',
      appId: 'WxBDBLPoSvMihNTnoWJXROpq-gzGzoHsz',
      appKey: 'n6Y96eiGJ8wAGJfv9t4uOEfd',
      avatar: 'monsterid',
      serverURLs: '',
      emojiMaps: "",
      visitor: false,
      ...option,
      path: isShuoshuo ? path : (option && option.path) || window.location.pathname
    }

    new Valine(valineConfig)
  }

  const loadValine = async (el, path) => {
    if (typeof Valine === 'function') {
      initValine(el, path)
    } else {
      await btf.getScript('https://cdn.jsdelivr.net/npm/valine/dist/Valine.min.js')
      initValine(el, path)
    }
  }

  if (isShuoshuo) {
    'Valine' === 'Valine'
      ? window.shuoshuoComment = { loadComment: loadValine }
      : window.loadOtherComment = loadValine
    return
  }

  if ('Valine' === 'Valine' || !false) {
    if (false) btf.loadComment(document.getElementById('vcomment'),loadValine)
    else setTimeout(loadValine, 0)
  } else {
    window.loadOtherComment = loadValine
  }
})()</script></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><i class="fas fa-spinner fa-pulse" id="loading-status" hidden="hidden"></i><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="text-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据加载中</span></div><div class="local-search-input"><input placeholder="搜索文章" type="text"/></div><hr/><div id="local-search-results"></div><div class="ais-Pagination" id="local-search-pagination" style="display:none;"><ul class="ais-Pagination-list"></ul></div><div id="local-search-stats"></div></div><div id="search-mask"></div><script src="/js/search/local-search.js"></script></div></div></body></html>
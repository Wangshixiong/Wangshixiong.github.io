<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>我画了十几张图，终于把GPT识字这件事，从头到尾讲透了 | 吏部侍郎</title><meta name="author" content="华子"><meta name="copyright" content="华子"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="很多文章在讲 tokenizer 的时候，往往从「词」「子词」直接开始，但如果你真的想理解 GPT 这类模型是怎么”看懂文字”的，我们可能要从头了解。需要强调的是，本文将要拆解的底层原理，不仅是GPT的魔法，同样也是驱动千问、豆包、DeepSeek、Kimi等所有顶尖大模型的共通基石。 这篇文章，我想完整记录：  文本是如何一步一步，从”电信号”，变成模型输入的一串整数 ID，又如何在模型输出后，">
<meta property="og:type" content="article">
<meta property="og:title" content="我画了十几张图，终于把GPT识字这件事，从头到尾讲透了">
<meta property="og:url" content="https://www.wenhuateng.top/posts/edc61d96/index.html">
<meta property="og:site_name" content="吏部侍郎">
<meta property="og:description" content="很多文章在讲 tokenizer 的时候，往往从「词」「子词」直接开始，但如果你真的想理解 GPT 这类模型是怎么”看懂文字”的，我们可能要从头了解。需要强调的是，本文将要拆解的底层原理，不仅是GPT的魔法，同样也是驱动千问、豆包、DeepSeek、Kimi等所有顶尖大模型的共通基石。 这篇文章，我想完整记录：  文本是如何一步一步，从”电信号”，变成模型输入的一串整数 ID，又如何在模型输出后，">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://wenhua-image.oss-cn-beijing.aliyuncs.com/%E5%BE%AE%E4%BF%A1%E5%85%AC%E4%BC%97%E5%8F%B7/%E5%B0%81%E9%9D%A2%E5%9B%BE3.png">
<meta property="article:published_time" content="2026-01-03T03:54:59.000Z">
<meta property="article:modified_time" content="2026-01-03T03:57:06.798Z">
<meta property="article:author" content="华子">
<meta property="article:tag" content="大模型">
<meta property="article:tag" content="AI技术">
<meta property="article:tag" content="Tokenizer">
<meta property="article:tag" content="BPE">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="https://wenhua-image.oss-cn-beijing.aliyuncs.com/%E5%BE%AE%E4%BF%A1%E5%85%AC%E4%BC%97%E5%8F%B7/%E5%B0%81%E9%9D%A2%E5%9B%BE3.png"><script type="application/ld+json">{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "我画了十几张图，终于把GPT识字这件事，从头到尾讲透了",
  "url": "https://www.wenhuateng.top/posts/edc61d96/",
  "image": "https://wenhua-image.oss-cn-beijing.aliyuncs.com/%E5%BE%AE%E4%BF%A1%E5%85%AC%E4%BC%97%E5%8F%B7/%E5%B0%81%E9%9D%A2%E5%9B%BE3.png",
  "datePublished": "2026-01-03T03:54:59.000Z",
  "dateModified": "2026-01-03T03:57:06.798Z",
  "author": [
    {
      "@type": "Person",
      "name": "华子",
      "url": "https://www.wenhuateng.top"
    }
  ]
}</script><link rel="shortcut icon" href="/img/favicon.svg"><link rel="canonical" href="https://www.wenhuateng.top/posts/edc61d96/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!false && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          theme === 'dark' ? activateDarkMode() : theme === 'light' ? activateLightMode() : null
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":false,"top_n_per_article":1,"unescape":false,"pagination":{"enable":false,"hitsPerPage":8},"languages":{"hits_empty":"未找到符合您查询的内容：${query}","hits_stats":"共找到 ${hits} 篇文章"}},
  translate: {"defaultEncoding":"繁","translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"簡"},
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false,"highlightFullpage":true,"highlightMacStyle":true},
  copy: {
    success: '复制成功',
    error: '复制失败',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyloadPlugin: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: true,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '我画了十几张图，终于把GPT识字这件事，从头到尾讲透了',
  isHighlightShrink: false,
  isToc: true,
  pageType: 'post'
}</script><meta name="generator" content="Hexo 7.3.0"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img text-center"><img src="/images/Happy.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data text-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">49</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">33</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">14</div></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="not-top-img fixed" id="page-header"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"><span class="site-name">吏部侍郎</span></a><a class="nav-page-title" href="/"><span class="site-name">我画了十几张图，终于把GPT识字这件事，从头到尾讲透了</span><span class="site-name"><i class="fa-solid fa-circle-arrow-left"></i><span>  返回首页</span></span></a></span><div id="menus"><div id="search-button"><span class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></span></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><div id="toggle-menu"><span class="site-page"><i class="fas fa-bars fa-fw"></i></span></div></div></nav></header><main class="layout" id="content-inner"><div id="post"><div id="post-info"><h1 class="post-title">我画了十几张图，终于把GPT识字这件事，从头到尾讲透了</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2026-01-03T03:54:59.000Z" title="发表于 2026-01-03 11:54:59">2026-01-03</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2026-01-03T03:57:06.798Z" title="更新于 2026-01-03 11:57:06">2026-01-03</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/AI%E6%8A%80%E6%9C%AF/">AI技术</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">总字数:</span><span class="word-count">2.3k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>7分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title=""><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">浏览量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div><article class="container post-content" id="article-container"><p><img src="https://wenhua-image.oss-cn-beijing.aliyuncs.com/%E5%BE%AE%E4%BF%A1%E5%85%AC%E4%BC%97%E5%8F%B7/%E5%B0%81%E9%9D%A2%E5%9B%BE3.png"><br>很多文章在讲 tokenizer 的时候，往往从「词」「子词」直接开始，但如果你真的想理解 GPT 这类模型是怎么”看懂文字”的，我们可能要从头了解。<br><strong>需要强调的是，本文将要拆解的底层原理，不仅是GPT的魔法，同样也是驱动千问、豆包、DeepSeek、Kimi等所有顶尖大模型的共通基石。</strong></p>
<p>这篇文章，我想完整记录：</p>
<blockquote>
<p><strong>文本是如何一步一步，从”电信号”，变成模型输入的一串整数 ID，又如何在模型输出后，被还原成人类能读懂的文字。</strong></p>
</blockquote>
<p><img src="https://wenhua-image.oss-cn-beijing.aliyuncs.com/%E5%BE%AE%E4%BF%A1%E5%85%AC%E4%BC%97%E5%8F%B7/Gemini_Generated_Image_68warh68warh68wa.png" alt="Toekn是如何诞生的"></p>
<h2 id="为什么不能只用字节？——从0-256开始的BPE之路"><a href="#为什么不能只用字节？——从0-256开始的BPE之路" class="headerlink" title="为什么不能只用字节？——从0-256开始的BPE之路"></a>为什么不能只用字节？——从0-256开始的BPE之路</h2><p>在任何语言模型、任何 tokenizer 出现之前，有一个不可绕过的事实：</p>
<blockquote>
<p><strong>计算机并不认识”字符”，只认识电压的高低。</strong></p>
</blockquote>
<p>这些电压状态，在逻辑上被抽象为 <strong>0 和 1（bit）</strong>。</p>
<p>但需要强调的是：</p>
<blockquote>
<p><strong>语言模型并不会直接处理 bit 级别的数据。</strong></p>
</blockquote>
<p>因为 bit 太底层、太长，而且不同编码方式会导致完全不同的 bit 序列。</p>
<p>真正进入 tokenizer 之前，所有文本都会先经过<strong>UTF-8 编码</strong>：</p>
<p><img src="https://wenhua-image.oss-cn-beijing.aliyuncs.com/%E5%BE%AE%E4%BF%A1%E5%85%AC%E4%BC%97%E5%8F%B7/Gemini_Generated_Image_3uwf4q3uwf4q3uwf.png" alt="UTF-8"></p>
<p>例如，<code>我爱中国 china</code>在 UTF-8 编码下，在计算机中存储运算的时候，其实是以一串<strong>字节序列</strong>进行的（字节就是计算机底层的那个二进制数字01）：</p>
<p><img src="https://wenhua-image.oss-cn-beijing.aliyuncs.com/%E5%BE%AE%E4%BF%A1%E5%85%AC%E4%BC%97%E5%8F%B7/%E6%88%91%E7%88%B1%E4%BD%A0%E4%B8%AD%E5%9B%BD.png" alt="utf-8编码"></p>
<p>其实，在这里，我们就已经算是产生了token，只不过每个token就是个8位的二进制数字。<br>如果直接把上面那一长串 0101 喂给模型，序列长度会爆炸（几十亿长度），模型的计算量绝对会爆炸的。 </p>
<p>所以我们需要将这个序列进行压缩。</p>
<p>我们知道：</p>
<ul>
<li>数学上，8 个二进制位能表示的状态总数是 $2^8 &#x3D; 256$ 种。</li>
<li>范围是从 <code>00000000</code> (0) 到 <code>11111111</code> (255)。</li>
</ul>
<p>所以，我们可以把<code>我爱中国 china</code>这样转换：</p>
<p>18✖️8&#x3D;144位长度—&gt;18个整数数字</p>
<p><img src="https://wenhua-image.oss-cn-beijing.aliyuncs.com/%E5%BE%AE%E4%BF%A1%E5%85%AC%E4%BC%97%E5%8F%B7/%E5%AD%97%E8%8A%82%E5%8E%8B%E7%BC%A9%E6%AF%94%E4%BE%8B.png" alt="字节压缩比例"></p>
<p>当然，18个整数还是有点长，所以我们还需要减少长度。</p>
<p>于是，一个非常工程化、但极其重要的想法出现了：</p>
<blockquote>
<p><strong>能不能把”经常一起出现的字节组合”，压缩成一个新的 token？</strong></p>
</blockquote>
<p>这就是 <strong>Byte-Pair Encoding（BPE）</strong> 的出发点。</p>
<p><img src="https://wenhua-image.oss-cn-beijing.aliyuncs.com/%E5%BE%AE%E4%BF%A1%E5%85%AC%E4%BC%97%E5%8F%B7/BPE%E7%9A%84%E5%BC%80%E5%A7%8B.png" alt="BPE的开始"></p>
<h2 id="BPE-算法是如何一步步”合并”出-Token-的？"><a href="#BPE-算法是如何一步步”合并”出-Token-的？" class="headerlink" title="BPE 算法是如何一步步”合并”出 Token 的？"></a>BPE 算法是如何一步步”合并”出 Token 的？</h2><p>通过刚刚的学习，我们知道初始状态：词表只有 256 个 token。</p>
<p>一切从最简单的状态开始：</p>
<p><strong>初始词表</strong>：<br>  <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&#123;0, 1, 2, ..., 255&#125;</span><br></pre></td></tr></table></figure><br>每一个 token 对应一个字节值。<br>训练语料被表示为类似这样的序列：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[..., 230, 136, 145, 231, 136, 177, 228, 184, 173, 229, 155, 189, 32, 99, 104, 105, 110, 97, ...]</span><br></pre></td></tr></table></figure>
<p><img src="https://wenhua-image.oss-cn-beijing.aliyuncs.com/%E5%BE%AE%E4%BF%A1%E5%85%AC%E4%BC%97%E5%8F%B7/BPE%E5%88%9D%E5%A7%8B%E7%8A%B6%E6%80%81.png" alt="BPE初始状态"></p>
<hr>
<p>BPE 会在<strong>整个训练语料</strong>中统计：</p>
<blockquote>
<p>哪些 <strong>相邻 token 对</strong> 出现得最频繁？</p>
</blockquote>
<p>假设它发现：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">(230,136,145)</span><br></pre></td></tr></table></figure>
<p>在大量中文文本中经常一起出现  （这是很多中文字符 UTF-8 编码的公共前缀）。<br>于是：</p>
<ol>
<li>它决定新增一个 token ID：<code>256</code></li>
<li>定义规则：  <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">256 = (230,136,145)</span><br></pre></td></tr></table></figure></li>
<li>然后在所有数据中统一替换<br>这时：</li>
</ol>
<blockquote>
<p><strong>token <code>257</code> 就完整地代表了汉字「我」</strong></p>
</blockquote>
<p><img src="https://wenhua-image.oss-cn-beijing.aliyuncs.com/%E5%BE%AE%E4%BF%A1%E5%85%AC%E4%BC%97%E5%8F%B7/%E5%90%88%E5%B9%B6.png" alt="合并"></p>
<p>同样的事情会发生在：</p>
<ul>
<li>「爱」</li>
<li>「中国」</li>
<li>甚至是整个「中国」</li>
<li>英文中的 <code>china</code></li>
</ul>
<p><img src="https://wenhua-image.oss-cn-beijing.aliyuncs.com/%E5%BE%AE%E4%BF%A1%E5%85%AC%E4%BC%97%E5%8F%B7/%E6%88%91%E7%88%B1%E4%B8%AD%E5%9B%BD.png" alt="最终token表"><br>  最终你可能会得到类似这样的结果：</p>
<table>
<thead>
<tr>
<th>Token ID</th>
<th>对应文本</th>
</tr>
</thead>
<tbody><tr>
<td>257</td>
<td>我</td>
</tr>
<tr>
<td>301</td>
<td>爱</td>
</tr>
<tr>
<td>812</td>
<td>中国</td>
</tr>
<tr>
<td>2048</td>
<td>china</td>
</tr>
</tbody></table>
<p>于是，<code>我爱中国 china</code>最终可能会被表示成：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[257, 301, 812, 2048]</span><br></pre></td></tr></table></figure>

<blockquote>
<p>原本十几个字节，现在变成了 <strong>4 个 token</strong>。</p>
</blockquote>
<hr>
<h2 id="BPE-一直合并到什么时候？"><a href="#BPE-一直合并到什么时候？" class="headerlink" title="BPE 一直合并到什么时候？"></a>BPE 一直合并到什么时候？</h2><p>这个过程会不断重复：</p>
<ul>
<li>字节 → 字</li>
<li>字 → 常见词</li>
<li>词 → 常见短语<br>直到：</li>
</ul>
<blockquote>
<p><strong>词表大小达到预设上限</strong></p>
</blockquote>
<p>比如 3 万、5 万、10 万级别。</p>
<h2 id="最终我们建立了词表"><a href="#最终我们建立了词表" class="headerlink" title="最终我们建立了词表"></a>最终我们建立了词表</h2><p>在 BPE 训练完成后，我们会得到一个<strong>确定的词表</strong>：</p>
<blockquote>
<p><strong>它本质上是：token ↔ 文本片段 的映射关系</strong></p>
</blockquote>
<ul>
<li><code>0 – 255</code>：基础字节 token（永远存在，兜底）</li>
<li><code>256 – N</code>：通过 BPE 学习到的子词、词、短语</li>
</ul>
<p><img src="https://wenhua-image.oss-cn-beijing.aliyuncs.com/%E5%BE%AE%E4%BF%A1%E5%85%AC%E4%BC%97%E5%8F%B7/%E8%AF%8D%E8%A1%A8.png" alt="词表"></p>
<p>最终这个词表会被应用于模型的训练阶段，和模型的输出阶段，其实大家可以理解成字典。就是通过字找到拼音，和通过拼音找到具体的字。<br><img src="https://wenhua-image.oss-cn-beijing.aliyuncs.com/%E5%BE%AE%E4%BF%A1%E5%85%AC%E4%BC%97%E5%8F%B7/%E6%98%A0%E5%B0%84.png" alt="映射"></p>
<p>当然，上面只是粗略的讲解了下token化的过程，还有一些细节没有说到。<br>比如，实际训练的时候，在进入BPE之前，有可能还会对原有的文本序列进行各种正则化清洗。这主要是依赖于我们最终的训练目标是什么。例如你如果训练的是写代码，那么<strong>4个空格这种必然需要是一个单独的token，所以再清洗阶段，就不能清洗这种格式</strong>。</p>
<p>那接下来呢？接下来会做什么呢？大家可能多多少少都知道一点点，<code>LLM</code>统计的是概率，那他的这个概率从何而来呢？</p>
<h2 id="嵌入embedding（就是向量化）"><a href="#嵌入embedding（就是向量化）" class="headerlink" title="嵌入embedding（就是向量化）"></a>嵌入embedding（就是向量化）</h2><p>我们刚刚讲了，有了一个token和文本的映射表。但是我们接下来，要建立一个静态的权重矩阵。他是一个二维矩阵，大概的形状可能是这样子：<code>[词表大小, 特征维度]</code></p>
<blockquote>
<p>**行数 (Rows)**：对应词表大小（例如 GPT-4 约为 100,277 行）。其实就是我们刚刚说的那个词表token的数量，每一行都对应了一个token。<br>**列数 (Columns)**：对应模型的特征维度（例如 Llama 3 为 4,096 列）。这个完全是随意定义的。它本质上就是在说，我要用多少个维度来描述这个token。</p>
</blockquote>
<p>就比如苹果，它是一个token，那它的大小、颜色、品种、种植地区、是水果还是手机，等等不同的维度描述。</p>
<p><strong>内容</strong>：每一行存储着一个特定的 Token ID 对应的<strong>特征向量</strong>。</p>
<ul>
<li>第 0 行：存储 Token <code>0</code> 的 4096 个浮点数。</li>
<li>第 257 行：存储 Token <code>257</code>（比如 “幻”）的 4096 个浮点数。<br><img src="https://wenhua-image.oss-cn-beijing.aliyuncs.com/%E5%BE%AE%E4%BF%A1%E5%85%AC%E4%BC%97%E5%8F%B7/%E6%9D%83%E9%87%8D%E7%9F%A9%E9%98%B5.png" alt="权重矩阵">  <br>这里，你可能会说，我理解这个矩阵是干什么的了，但是他的初始值是什么呢？<strong>其实这里是完全随机生成的一个初始值</strong>，就是调用了一个随机函数生成的。后面的训练过程中，所谓的训练，其实在我的理解看来，就是在更新这个权重矩阵的值。让他的值更加接近真实。在预训练完成以后，这个参数也就固定下来了。</li>
</ul>
<p>实际大模型训练的时候，就会这样去构建一个输入的高维矩阵，或者说张量，大家不要害怕这个名词。她可以这么简单的理解：</p>
<p>比如<code>我爱中国 china</code>，假设它对应4个token，那每一个token，取出来的向量就是[4096个特征值]，但是我们向模型输入的时候，就变成了这样的矩阵：<br>[ <code>我</code>[4096个特征值],<br><code>爱</code>[4096个特征值],<br><code>中国</code>[4096个特征值],<br><code>china</code>[4096个特征值]]</p>
<p>好抽象啊，请看图：<br><img src="https://wenhua-image.oss-cn-beijing.aliyuncs.com/%E5%BE%AE%E4%BF%A1%E5%85%AC%E4%BC%97%E5%8F%B7/%E5%BC%A0%E9%87%8F.png" alt="张量"></p>
<p>当然，这只是一句话的样子。大家想一下，我们训练肯定不会一句话一句话来训练，我们如果一次性输入32句话，那对模型的输入矩阵是不是就会变成一个3D立方体的3维矩阵呢：<br><img src="https://wenhua-image.oss-cn-beijing.aliyuncs.com/%E5%BE%AE%E4%BF%A1%E5%85%AC%E4%BC%97%E5%8F%B7/3d%E5%BC%A0%E9%87%8F-1.png" alt="3d张量"></p>
<p>当然，到了这里还没有完成，因为模型，其实还不知道token的具体位置，因为<code>我爱中国</code>，和<code>中国爱我</code>，明显意思是不一样的。但是如果在矩阵中，他们的权重是一样的话，那么他们的加权求和的值必然是一样的。所以就会对模型训练造成极大的困扰。<br><img src="https://wenhua-image.oss-cn-beijing.aliyuncs.com/%E5%BE%AE%E4%BF%A1%E5%85%AC%E4%BC%97%E5%8F%B7/%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81-1.png" alt="为什么要位置编码"></p>
<p>所以，我们需要给每一个token一个位置信息，这就好比虽然都叫‘吏部侍郎’，但我给第一个人发了个‘朝阳区’的身份证，给第二个人发了个‘通州区’的身份证。<br><img src="https://wenhua-image.oss-cn-beijing.aliyuncs.com/%E5%BE%AE%E4%BF%A1%E5%85%AC%E4%BC%97%E5%8F%B7/%E5%90%8F%E9%83%A8%E4%BE%8D%E9%83%8E-1.png" alt="吏部侍郎"><br>但是，最先进的大模型（比如DeepSeek）觉得光发身份证还不够聪明。它们用了一种更天才的方法：<strong>不是发固定的地址，而是给每人发一块‘表’。</strong></p>
<p>它是这么做的：<br>• 你是第 1 个字？请把你向量里的指针向左拨动 <strong>1度</strong>。<br>• 你是第 2 个字？请把你向量里的指针向左拨动 <strong>2度</strong>。<br>• 你是第 100 个字？请转动 <strong>100度</strong>。</p>
<p><img src="https://wenhua-image.oss-cn-beijing.aliyuncs.com/%E5%BE%AE%E4%BF%A1%E5%85%AC%E4%BC%97%E5%8F%B7/%E5%A4%B9%E8%A7%922-1.png" alt="夹角2"><br><strong>为什么要这么麻烦去‘旋转’呢？</strong> 因为对于模型来说，它不关心你到底住在北京还是上海（绝对位置），它只关心<strong>‘你俩离得近不近’</strong>（相对位置）。<br>通过旋转，奇迹发生了：无论这两个字搬到了文章的哪里，只要它们是相邻的，它们指针之间的<strong>夹角差</strong>永远是 1度。模型只要一量夹角，瞬间秒懂：‘哦，这俩货是一起的！<br><img src="https://wenhua-image.oss-cn-beijing.aliyuncs.com/%E5%BE%AE%E4%BF%A1%E5%85%AC%E4%BC%97%E5%8F%B7/%E5%A4%B9%E8%A7%92.png" alt="夹角"><br>恭喜你，你已经悟透了目前统治大模型界的各种模型背后的核心魔法——<strong>RoPE（旋转位置编码）</strong>。</p>
<p>至此，LLM预训练的token和embedding，大家应该有一个简单的了解了。</p>
<p>#AI #AIGC #GPT #大语言模型 #Tokenizer #Embedding #RoPE #人工智能</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a href="https://www.wenhuateng.top">华子</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a href="https://www.wenhuateng.top/posts/edc61d96/">https://www.wenhuateng.top/posts/edc61d96/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来源 <a href="https://www.wenhuateng.top" target="_blank">吏部侍郎</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E5%A4%A7%E6%A8%A1%E5%9E%8B/">大模型</a><a class="post-meta__tags" href="/tags/AI%E6%8A%80%E6%9C%AF/">AI技术</a><a class="post-meta__tags" href="/tags/Tokenizer/">Tokenizer</a><a class="post-meta__tags" href="/tags/BPE/">BPE</a></div><div class="post-share"><div class="social-share" data-image="https://wenhua-image.oss-cn-beijing.aliyuncs.com/%E5%BE%AE%E4%BF%A1%E5%85%AC%E4%BC%97%E5%8F%B7/%E5%B0%81%E9%9D%A2%E5%9B%BE3.png" data-sites="wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><a class="pagination-related" href="/posts/65084fb8/" title="Claude Code斜杠命令进阶：从自动化提交到智能分支管理"><img class="cover" src="https://images.unsplash.com/photo-1617791160505-6f00504e3519" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="info"><div class="info-1"><div class="info-item-1">上一篇</div><div class="info-item-2">Claude Code斜杠命令进阶：从自动化提交到智能分支管理</div></div><div class="info-2"><div class="info-item-1">前言在使用 Claude Code 的过程中，我发现了一个非常实用的斜杠命令：/git-commit。这个命令实现了从简单的自动化提交到智能分支管理的完整演进过程。本文将记录这个命令从最初版本到现在的完整演变历程。  版本1.0：基础自动化提交需求背景最初的需求很简单：每次写完代码后，都要手动执行一系列 git 操作：  git add . git status 查看变更 git diff --cached 查看具体修改内容 手动思考写什么 commit message git commit -m &quot;xxx&quot;  这个过程虽然简单，但重复执行非常繁琐。 实现方案创建了第一个版本的 /.claude/commands/git-commit.md： ---description: &quot;【全自动】一键执行 git add . 并自动生成信息提交&quot;argument-hint: &quot;[可选：指定提交意图或关键词]&quot;allowed-tools: Bash(git add:*), Bash(git diff:*), Bash(git sta...</div></div></div></a><a class="pagination-related" href="/posts/8bcaf6c/" title="最高效的学习其实是“不学习”？Gemini 3.0 揭示了AI时代的“拿来主义”"><img class="cover" src="https://wenhua-image.oss-cn-beijing.aliyuncs.com/%E5%BE%AE%E4%BF%A1%E5%85%AC%E4%BC%97%E5%8F%B7/file-20251123235350767.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="info text-right"><div class="info-1"><div class="info-item-1">下一篇</div><div class="info-item-2">最高效的学习其实是“不学习”？Gemini 3.0 揭示了AI时代的“拿来主义”</div></div><div class="info-2"><div class="info-item-1">最近大家看Gemini3.0可能了解了很多它在前端代码生成方面的能力。但忽略了它的最强的一个应用场景：就是把它当做任何一个软件的高级专家去使用。这个用法能将我们学习新工具（如影刀、Dify、Hexo）的时间从几天压缩到几分钟，跳过枯燥的学习过程，直接拿结果。当然，如果这个软件满足以下条件任意之一会更好（因为Gemini 3.0强大的上下文窗口能力)：  在网上有很多教程  官方文档写的非常好  软件开源   下面我们以影刀RPA为例，简单的给大家演示一下过程。 操作过程先将我们的需求简单描述一下，让Gemini 3.0帮我们优化下提示词。因为我本身对影刀有一些简单的了解，知道它很多工具都是基于python处理的，也知道他对python有非常好的支持，所以我下面的初版提示词提到了python脚本。但是如果大家没用过，其实它也会给一个完全是影刀RPA的指令的完成方式，但是会相对会需要你多沟通几次。你可以这样问，还有没有其他操作起来更加简单地方案呢？ 我现在有一个业务需求，业务人员每天都会受到一封固定邮件，附件内容也是固定的是一个excel，业务人员收到以后，需要将附件下载，然后解压缩...</div></div></div></a></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><a class="pagination-related" href="/posts/6726469e/" title="不止出行规划！看MCP+高德地图在信贷风控的新应用"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-04-06</div><div class="info-item-2">不止出行规划！看MCP+高德地图在信贷风控的新应用</div></div><div class="info-2"><div class="info-item-1">MCP（Model Context Protocol）模型上下文协议，听起来非常神秘，就像是TCP协议一样。大家应该都听说过他， 尤其是在Manus出来以后。他到底是什么呢？能做什么呢？这里我和大家一起学习一下，我们先从他能做什么开始。 1. 三个高德地图MCP的场景 以下所有场景使用的工具都是Cursor。  1.1 先从玩开始现在的大模型LLM一定是从提示词开始的： 【行程规划需求-**必须使用高德MCP**，不要基于你自身经验，要依据高德的结果】# 目的地：北京# 出行人数：2人（夫妻）# 时间范围：4月30日晚抵达 - 5月5日（共5天4晚）# 需求重点：- 经典景点覆盖（故宫/长城/颐和园等必游地）- 特色体验推荐（胡同文化/老字号美食/夜景）- 住宿建议（优选王府井/前门等交通便利区域）- 交通方案（机场到市区+景点间通勤）- 人流预警（五一高峰期特别注意事项）# 附加需求：- 适合情侣的浪漫体验推荐- 每日合理步行强度安排- 考虑天气，备选雨天方案- 可考虑1天近郊行程（如古北水镇）# 给我详细的行程规划，包括交通方式，预计所需时间。 下面是gemini-2.5调用...</div></div></div></a><a class="pagination-related" href="/posts/58184c34/" title="当产品经理开始AI编程(二)：从一次失败的重构中领悟的AI协作之道"><img class="cover" src="https://wenhua-image.oss-cn-beijing.aliyuncs.com/%E5%BE%AE%E4%BF%A1%E5%85%AC%E4%BC%97%E5%8F%B7/20250712131403872.png" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-07-11</div><div class="info-item-2">当产品经理开始AI编程(二)：从一次失败的重构中领悟的AI协作之道</div></div><div class="info-2"><div class="info-item-1">因为最开始的提示词插件版本在小屏上展示很不友好，所以起了重构UI的心思。&#x20;**我以为这只是一个简单的UI美化任务，最多一两天就能搞定。没想到，这个‘小念头’却把我拖入了一场持续2周的重构深渊&#x20;**。&#x20;大家应该还记得我们第一版的UI提示词展示的时候，非常大，占位置，因为他是一个卡片的形式。&#x20;大家也可以看下 当产品经理开始AI编程：一个提示词插件的诞生记与我的AI协作心得 回忆下。   从头铁硬改到灵魂拷问第一回合：AI大力出奇迹？结果BUG遍地 比如Deepseek设计的一版：&#x20;   当然Gemini也设计过很多版本。但是实际执行时，我会发现，Trae改出来的UI， **会导致大量的功能性BUG，甚至页面都打不开&#x20;**。&#x20;这个时候，我感觉到了不对，我只是重构了下UI或者说CSS，怎么会导致功能不可用呢？而且我已经在提示词里面加了最小化修改等等的要求。 第二回合：问题在AI，还是在我？难道是我没有找到Trae的正确打开方式吗？&#x20;所以这个时候，我就开始让Gemini开启了DeepResearch模式，来研究...</div></div></div></a><a class="pagination-related" href="/posts/daac02c6/" title="当产品经理拿起AI“代码笔”：一个提示词插件的诞生记与我的AI协作心得"><img class="cover" src="https://wenhua-image.oss-cn-beijing.aliyuncs.com/%E5%BE%AE%E4%BF%A1%E5%85%AC%E4%BC%97%E5%8F%B7/20250712130513585.png" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-06-27</div><div class="info-item-2">当产品经理拿起AI“代码笔”：一个提示词插件的诞生记与我的AI协作心得</div></div><div class="info-2"><div class="info-item-1">消失差不多快三周了，去干什么了呢。去搞AI编程了。就纯粹的迷上了AI编程的成就感。 起因是，看到自己关注的一个博主@云舒，发了一篇公众号文章，讲述他的AI编程过程，他做了一个提示词管理的插件出来，我也就突然想，我之前一直做的都是使用大模型做一个网页，让他最多也就是使用html画一个产品的原型出来，实际其实并没有尝试过AI编程做一个东西出来。 作为一个立志要懂业务和技术的AI产品来说，这怎么能行呢。我需要知道AI编程能做什么，能不能做出来，只看别人写的是不够的。  纸上得来终觉浅，绝知此事要躬行。  因此说干就干，从6月9号开始，到6月22号结束，工作日每天晚上干3个小时，周末了就多干一会，终于也搞了一个提示词浏览器插件出来。  核心功能：  提示词的增删改查。  大模型对话网站输入框快速唤醒提示词搜索框。  云端同步。   本次开发使用的AI：  Trae（80%的工作），量大管饱还便宜，最主要支持国内付款（PS：600次，我现在只剩40次，走了太多弯路）。  Gemini（18%的工作），写需求，联合Trae一起排查解决问题。  Deepseek（2%的工作），搞了几个页面设计...</div></div></div></a><a class="pagination-related" href="/posts/75c20f19/" title="试了高德+Edgeone Pages 的 MCP 组合拳后，我画出了这份详细的数据流图解"><img class="cover" src="https://wenhua-image.oss-cn-beijing.aliyuncs.com/%E5%BE%AE%E4%BF%A1%E5%85%AC%E4%BC%97%E5%8F%B7/EdgeonePage/Snipaste_2025-07-11_23-50-14.png" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-05-11</div><div class="info-item-2">试了高德+Edgeone Pages 的 MCP 组合拳后，我画出了这份详细的数据流图解</div></div><div class="info-2"><div class="info-item-1">最近在探索MCP相关的服务生态，然后就发现了腾讯所发布的这个Edgeone Pages。让我感觉自己开了挂。使用的过程中又对MCP的数据流研究了下。 1. 从Edgeone Pages的案例开始1.1 案例演示哈，大家都知道，我前两天在第一次学习MCP的时候做了一个案例，使用高德地图的MCP服务只做了一个旅游的行程规划。步骤是这样的：这个中间需要我自己手工介入很多步，但是现在，我可以直接将两个提示词进行合并，借助高德MCP和腾讯的Edgeone Pages服务就可以一步直接得到一个已经部署好的可以公开访问的网页链接。感觉各种方面，Agent起风了。为我的老板出差生成行程规划，并且一键部署网页。 # 任务：生成老板北京-上海当日高铁往返行程的HTML代码，使用高德MCP服务和EdgeonePage服务。## 扮演角色你是一位**精通信息可视化和前端开发的行政助理/差旅规划专家**，并能**对接和利用MCP（出行相关服务）**获取实时或预测数据。## 核心目标为我的老板创建一份北京⇌上海当日高铁往返行程单的**HTML代码**。这段代码渲染后需呈现为一个**极简、视觉清晰、重点突出*...</div></div></div></a><a class="pagination-related" href="/posts/a8573b07/" title="字节「扣子空间」如何赋能一线保险业务？一个活动策划案例带来的启示"><img class="cover" src="https://wenhua-image.oss-cn-beijing.aliyuncs.com/%E5%BE%AE%E4%BF%A1%E5%85%AC%E4%BC%97%E5%8F%B7/20250712130010103.png" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-04-27</div><div class="info-item-2">字节「扣子空间」如何赋能一线保险业务？一个活动策划案例带来的启示</div></div><div class="info-2"><div class="info-item-1">关注AI领域动态的，可能知道字节跳动新发布了扣子空间这个产品的beta版本。 这个跟原来的扣子工作流是个完全不一样的产品，扣子的工作流还需要我们人为拖拉拽，先人工再智能，但是扣子空间不需要了，我们只需要提需求就可以了。 我最近一直在探索使用MCP服务，扣子空间也是支持MCP服务的，以下是现在官方所支持的MCP服务。接下来，我们还是从一个案例的演示，给大家抛砖引玉。   起源今年春节过完，Deepseek带来了一阵大模型热，当时公司呢，让我做了一个关于大模型在保险公司内的应用培训。当时我演示了一个案例：大模型可以用来生成活动策划方案。因为是演示，所以我的提示词很简单： **目标**：六一儿童节即将到来，我需要组织一场活动，来宣传我们公司代理的保险产品，最好可以直接当场签约，但是我不希望参加活动的人不开心。**背景**：我是一个保险代理人，我们公司代理了各种保险产品，六一儿童节，我想主推和孩子有关的相关保险产品，但是其他年龄产品的我也想推。**活动时间**：计划六一当天。**活动预算**：10万元。**活动预计参与人数**：50个家庭。**活动人员**：我司当前已育有孩子的家庭，孩子...</div></div></div></a></div></div><hr class="custom-hr"/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div class="vcomment" id="vcomment"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info text-center"><div class="avatar-img"><img src="/images/Happy.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info-name">华子</div><div class="author-info-description">一个懂业务的AI产品经理</div><div class="site-data"><a href="/archives/"><div class="headline">文章</div><div class="length-num">49</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">33</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">14</div></a></div><div class="card-info-social-icons"><a class="social-icon" href="https://github.com/Wangshixiong" target="_blank" title="Github"><i class="fab fa-github" style="color: #24292e;"></i></a><a class="social-icon" href="https://wenhua-image.oss-cn-beijing.aliyuncs.com/%E5%BE%AE%E4%BF%A1%E5%85%AC%E4%BC%97%E5%8F%B7/wechat.jpg" target="_blank" title="微信"><i class="fab fa-weixin" style="color: #07c160;"></i></a></div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content is-expand"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%BA%E4%BB%80%E4%B9%88%E4%B8%8D%E8%83%BD%E5%8F%AA%E7%94%A8%E5%AD%97%E8%8A%82%EF%BC%9F%E2%80%94%E2%80%94%E4%BB%8E0-256%E5%BC%80%E5%A7%8B%E7%9A%84BPE%E4%B9%8B%E8%B7%AF"><span class="toc-number">1.</span> <span class="toc-text">为什么不能只用字节？——从0-256开始的BPE之路</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#BPE-%E7%AE%97%E6%B3%95%E6%98%AF%E5%A6%82%E4%BD%95%E4%B8%80%E6%AD%A5%E6%AD%A5%E2%80%9D%E5%90%88%E5%B9%B6%E2%80%9D%E5%87%BA-Token-%E7%9A%84%EF%BC%9F"><span class="toc-number">2.</span> <span class="toc-text">BPE 算法是如何一步步”合并”出 Token 的？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#BPE-%E4%B8%80%E7%9B%B4%E5%90%88%E5%B9%B6%E5%88%B0%E4%BB%80%E4%B9%88%E6%97%B6%E5%80%99%EF%BC%9F"><span class="toc-number">3.</span> <span class="toc-text">BPE 一直合并到什么时候？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%9C%80%E7%BB%88%E6%88%91%E4%BB%AC%E5%BB%BA%E7%AB%8B%E4%BA%86%E8%AF%8D%E8%A1%A8"><span class="toc-number">4.</span> <span class="toc-text">最终我们建立了词表</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%B5%8C%E5%85%A5embedding%EF%BC%88%E5%B0%B1%E6%98%AF%E5%90%91%E9%87%8F%E5%8C%96%EF%BC%89"><span class="toc-number">5.</span> <span class="toc-text">嵌入embedding（就是向量化）</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/posts/1b26e8ea/" title="我只是想留住一个投资人的思考，结果学会了如何让 AI 替我干脏活"><img src="https://wenhua-image.oss-cn-beijing.aliyuncs.com/%E5%BE%AE%E4%BF%A1%E5%85%AC%E4%BC%97%E5%8F%B7/image-20260107002859783.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="我只是想留住一个投资人的思考，结果学会了如何让 AI 替我干脏活"/></a><div class="content"><a class="title" href="/posts/1b26e8ea/" title="我只是想留住一个投资人的思考，结果学会了如何让 AI 替我干脏活">我只是想留住一个投资人的思考，结果学会了如何让 AI 替我干脏活</a><time datetime="2026-01-06T13:56:00.000Z" title="发表于 2026-01-06 21:56:00">2026-01-06</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/posts/65084fb8/" title="Claude Code斜杠命令进阶：从自动化提交到智能分支管理"><img src="https://images.unsplash.com/photo-1617791160505-6f00504e3519" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Claude Code斜杠命令进阶：从自动化提交到智能分支管理"/></a><div class="content"><a class="title" href="/posts/65084fb8/" title="Claude Code斜杠命令进阶：从自动化提交到智能分支管理">Claude Code斜杠命令进阶：从自动化提交到智能分支管理</a><time datetime="2026-01-03T04:30:45.000Z" title="发表于 2026-01-03 12:30:45">2026-01-03</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/posts/edc61d96/" title="我画了十几张图，终于把GPT识字这件事，从头到尾讲透了"><img src="https://wenhua-image.oss-cn-beijing.aliyuncs.com/%E5%BE%AE%E4%BF%A1%E5%85%AC%E4%BC%97%E5%8F%B7/%E5%B0%81%E9%9D%A2%E5%9B%BE3.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="我画了十几张图，终于把GPT识字这件事，从头到尾讲透了"/></a><div class="content"><a class="title" href="/posts/edc61d96/" title="我画了十几张图，终于把GPT识字这件事，从头到尾讲透了">我画了十几张图，终于把GPT识字这件事，从头到尾讲透了</a><time datetime="2026-01-03T03:54:59.000Z" title="发表于 2026-01-03 11:54:59">2026-01-03</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/posts/8bcaf6c/" title="最高效的学习其实是“不学习”？Gemini 3.0 揭示了AI时代的“拿来主义”"><img src="https://wenhua-image.oss-cn-beijing.aliyuncs.com/%E5%BE%AE%E4%BF%A1%E5%85%AC%E4%BC%97%E5%8F%B7/file-20251123235350767.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="最高效的学习其实是“不学习”？Gemini 3.0 揭示了AI时代的“拿来主义”"/></a><div class="content"><a class="title" href="/posts/8bcaf6c/" title="最高效的学习其实是“不学习”？Gemini 3.0 揭示了AI时代的“拿来主义”">最高效的学习其实是“不学习”？Gemini 3.0 揭示了AI时代的“拿来主义”</a><time datetime="2025-11-23T16:46:40.000Z" title="发表于 2025-11-24 00:46:40">2025-11-24</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/posts/db1bad86/" title="Dify知识库图文混排到底应该怎么做，两种主流方案，一次讲清！"><img src="https://wenhua-image.oss-cn-beijing.aliyuncs.com/%E5%BE%AE%E4%BF%A1%E5%85%AC%E4%BC%97%E5%8F%B7/%E5%B0%81%E9%9D%A2%E5%9B%BE1.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Dify知识库图文混排到底应该怎么做，两种主流方案，一次讲清！"/></a><div class="content"><a class="title" href="/posts/db1bad86/" title="Dify知识库图文混排到底应该怎么做，两种主流方案，一次讲清！">Dify知识库图文混排到底应该怎么做，两种主流方案，一次讲清！</a><time datetime="2025-11-15T16:46:40.000Z" title="发表于 2025-11-16 00:46:40">2025-11-16</time></div></div></div></div></div></div></main><footer id="footer"><div class="footer-other"><div class="footer-copyright"><span class="copyright">&copy;&nbsp;2025 - 2026 By 华子</span><span class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo 7.3.0</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly 5.5.0</a></span></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="translateLink" type="button" title="简繁转换">2</button><button id="darkmode" type="button" title="日间和夜间模式切换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="前往评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.umd.min.js"></script><div class="js-pjax"><script>(() => {
  const runMermaid = ele => {
    window.loadMermaid = true
    const theme = document.documentElement.getAttribute('data-theme') === 'dark' ? 'dark' : 'default'

    ele.forEach((item, index) => {
      const mermaidSrc = item.firstElementChild
      const mermaidThemeConfig = `%%{init:{ 'theme':'${theme}'}}%%\n`
      const mermaidID = `mermaid-${index}`
      const mermaidDefinition = mermaidThemeConfig + mermaidSrc.textContent

      const renderFn = mermaid.render(mermaidID, mermaidDefinition)
      const renderMermaid = svg => {
        mermaidSrc.insertAdjacentHTML('afterend', svg)
      }

      // mermaid v9 and v10 compatibility
      typeof renderFn === 'string' ? renderMermaid(renderFn) : renderFn.then(({ svg }) => renderMermaid(svg))
    })
  }

  const codeToMermaid = () => {
    const codeMermaidEle = document.querySelectorAll('pre > code.mermaid')
    if (codeMermaidEle.length === 0) return

    codeMermaidEle.forEach(ele => {
      const preEle = document.createElement('pre')
      preEle.className = 'mermaid-src'
      preEle.hidden = true
      preEle.textContent = ele.textContent
      const newEle = document.createElement('div')
      newEle.className = 'mermaid-wrap'
      newEle.appendChild(preEle)
      ele.parentNode.replaceWith(newEle)
    })
  }

  const loadMermaid = () => {
    if (false) codeToMermaid()
    const $mermaid = document.querySelectorAll('#article-container .mermaid-wrap')
    if ($mermaid.length === 0) return

    const runMermaidFn = () => runMermaid($mermaid)
    btf.addGlobalFn('themeChange', runMermaidFn, 'mermaid')
    window.loadMermaid ? runMermaidFn() : btf.getScript('https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js').then(runMermaidFn)
  }

  btf.addGlobalFn('encrypt', loadMermaid, 'mermaid')
  window.pjax ? loadMermaid() : document.addEventListener('DOMContentLoaded', loadMermaid)
})()</script><script>(() => {
  const isShuoshuo = GLOBAL_CONFIG_SITE.pageType === 'shuoshuo'
  const option = null

  const initValine = (el, path) => {
    if (isShuoshuo) {
      window.shuoshuoComment.destroyValine = () => {
        if (el.children.length) {
          el.innerHTML = ''
          el.classList.add('no-comment')
        }
      }
    }

    const valineConfig = {
      el: '#vcomment',
      appId: 'WxBDBLPoSvMihNTnoWJXROpq-gzGzoHsz',
      appKey: 'n6Y96eiGJ8wAGJfv9t4uOEfd',
      avatar: 'monsterid',
      serverURLs: '',
      emojiMaps: "",
      visitor: false,
      ...option,
      path: isShuoshuo ? path : (option && option.path) || window.location.pathname
    }

    new Valine(valineConfig)
  }

  const loadValine = async (el, path) => {
    if (typeof Valine === 'function') {
      initValine(el, path)
    } else {
      await btf.getScript('https://cdn.jsdelivr.net/npm/valine/dist/Valine.min.js')
      initValine(el, path)
    }
  }

  if (isShuoshuo) {
    'Valine' === 'Valine'
      ? window.shuoshuoComment = { loadComment: loadValine }
      : window.loadOtherComment = loadValine
    return
  }

  if ('Valine' === 'Valine' || !false) {
    if (false) btf.loadComment(document.getElementById('vcomment'),loadValine)
    else setTimeout(loadValine, 0)
  } else {
    window.loadOtherComment = loadValine
  }
})()</script></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><i class="fas fa-spinner fa-pulse" id="loading-status" hidden="hidden"></i><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="text-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据加载中</span></div><div class="local-search-input"><input placeholder="搜索文章" type="text"/></div><hr/><div id="local-search-results"></div><div class="ais-Pagination" id="local-search-pagination" style="display:none;"><ul class="ais-Pagination-list"></ul></div><div id="local-search-stats"></div></div><div id="search-mask"></div><script src="/js/search/local-search.js"></script></div></div></body></html>